<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Bamboo&#39;s Blog</title>
  
  <subtitle>心路</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://bamboox.online/"/>
  <updated>2020-03-28T18:02:30.870Z</updated>
  <id>https://bamboox.online/</id>
  
  <author>
    <name>bamboo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>在k8s上部署ftp</title>
    <link href="https://bamboox.online/2020/03/28/ftp-on-k8s/"/>
    <id>https://bamboox.online/2020/03/28/ftp-on-k8s/</id>
    <published>2020-03-28T22:39:50.000Z</published>
    <updated>2020-03-28T18:02:30.870Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ftp-image"><a href="#ftp-image" class="headerlink" title="ftp image"></a>ftp image</h1><p>vsftpd<br>具体参数参考<br>`<a href="https://github.com/fauria/docker-vsftpd``" target="_blank" rel="noopener">https://github.com/fauria/docker-vsftpd``</a></p><h2 id="ftp模式"><a href="#ftp模式" class="headerlink" title="ftp模式"></a>ftp模式</h2><p>FTP协议有两种工作方式：PORT方式和PASV方式，中文意思为主动式和被动式</p><ol><li>PORT（主动）方式的连接过程是：客户端向服务器的FTP端口（默认是21）发送连接请求，服务器接受连接，建立一条命令链路当需要传送数据时，客户端在命令链路上用PORT命令告诉服务器：我打开了XXXX端口，你过来连接我于是服务器从20端口向客户端的XXXX端口发送连接请求，建立一条数据链路来传送数据</li><li>PASV（被动）方式的连接过程是：客户端向服务器的FTP端口（默认是21）发送连接请求，服务器接受连接，建立一条命令链路当需要传送数据时，服务器在命令链路上用PASV命令告诉客户端：我打开了XXXX端口，你过来连接我于是客户端向服务器的XXXX端口发送连接请求，建立一条数据链路来传送数据</li></ol><blockquote><p>概括:</p></blockquote><ol><li>主动模式: 服务器向客户端敲门，然后客户端开门</li><li>被动模式: 客户端向服务器敲门，然后服务器开门</li></ol><h1 id="ftp-on-docker"><a href="#ftp-on-docker" class="headerlink" title="ftp on docker"></a>ftp on docker</h1><p>一般选用被动模式,服务端打开端口这样比较容易控制</p><pre class="line-numbers language-sh"><code class="language-sh">docker run -d -v /my/data/directory:/home/vsftpd \-p 20:20 -p 21:21 -p 21100-21110:21100-21110 \-e FTP_USER=myuser -e FTP_PASS=mypass -e PASV_ADDRESS_ENABLE=YES \-e PASV_ADDRESS=127.0.0.1 -e PASV_MIN_PORT=21100 -e PASV_MAX_PORT=21110 \--name vsftpd --restart=always fauria/vsftpd<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>测试</p><pre class="line-numbers language-sh"><code class="language-sh"> $ ftpftp> open localhostConnected to localhost.220 (vsFTPd 3.0.2)Name (localhost:bamboo): myuser331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp> ls /500 Illegal PORT command.ftp: bind: Address already in useftp> passive Passive mode on.ftp> ls /227 Entering Passive Mode (127,0,0,1,82,116).150 Here comes the directory listing.226 Directory send OK.ftp> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="ftp-on-k8s"><a href="#ftp-on-k8s" class="headerlink" title="ftp on k8s"></a>ftp on k8s</h1><p>注意</p><ol><li>ftp 需要被动模式</li><li>k8s svc Headless(因为k8s kube proxy 转发不确定确定哪些端口是需要转发的，所有只能通过k8s dns 直接解析podIP, 而不是clusterIP)</li></ol><p>ftp deployment</p><pre class="line-numbers language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1beta1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> my<span class="token punctuation">-</span>ftp<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true">#replicas: 3</span>  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>      <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token key atrule">app</span><span class="token punctuation">:</span> my<span class="token punctuation">-</span>ftp    <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">hostNetwork</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> my<span class="token punctuation">-</span>ftp<span class="token punctuation">-</span>container        <span class="token key atrule">image</span><span class="token punctuation">:</span> fauria/vsftpd        <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> Never        <span class="token key atrule">ports</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">containerPort</span><span class="token punctuation">:</span> <span class="token number">21</span>          <span class="token key atrule">protocol</span><span class="token punctuation">:</span> TCP          <span class="token key atrule">name</span><span class="token punctuation">:</span> <span class="token string">"ftp-server"</span>        <span class="token key atrule">env</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> FTP_USER          <span class="token key atrule">value</span><span class="token punctuation">:</span> <span class="token string">"myuser"</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> FTP_PASS          <span class="token key atrule">value</span><span class="token punctuation">:</span> <span class="token string">"mypass"</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> PASV_MIN_PORT          <span class="token key atrule">value</span><span class="token punctuation">:</span> <span class="token string">"21100"</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> PASV_MAX_PORT          <span class="token key atrule">value</span><span class="token punctuation">:</span> <span class="token string">"21110"</span>        <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /home/vsftpd          <span class="token key atrule">name</span><span class="token punctuation">:</span> nfs<span class="token punctuation">-</span>volume      <span class="token key atrule">volumes</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> nfs<span class="token punctuation">-</span>volume        <span class="token key atrule">hostPath</span><span class="token punctuation">:</span>         <span class="token key atrule">path</span><span class="token punctuation">:</span> /data         <span class="token key atrule">type</span><span class="token punctuation">:</span> DirectoryOrCreate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ftp Service Headless</p><pre class="line-numbers language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Service<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> my<span class="token punctuation">-</span>ftp<span class="token punctuation">-</span>service  <span class="token key atrule">labels</span><span class="token punctuation">:</span>    <span class="token key atrule">app</span><span class="token punctuation">:</span> my<span class="token punctuation">-</span>ftp<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> ClusterIP  <span class="token key atrule">clusterIP</span><span class="token punctuation">:</span> None  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">app</span><span class="token punctuation">:</span> my<span class="token punctuation">-</span>ftp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>test deploy</p><pre><code>apiVersion: apps/v1kind: Deploymentmetadata:  labels:    app: debug  name: debugspec:  replicas: 1  selector:    matchLabels:      app: debug  template:    metadata:      labels:        app: debug    spec:      #nodeSelector:      #  node-role.kubernetes.io/master: &quot;&quot;      containers:      - image: nicolaka/netshoot         name: netshoot        command: [ &quot;/bin/bash&quot;, &quot;-ce&quot;, &quot;tail -f /dev/null&quot; ]        imagePullPolicy: Never</code></pre><p>执行测试下载链接(手工在ftp目录创建一个文件)</p><pre><code>wget ftp://myuser:mypass@my-ftp-service/1</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ftp-image&quot;&gt;&lt;a href=&quot;#ftp-image&quot; class=&quot;headerlink&quot; title=&quot;ftp image&quot;&gt;&lt;/a&gt;ftp image&lt;/h1&gt;&lt;p&gt;vsftpd&lt;br&gt;具体参数参考&lt;br&gt;`&lt;a href=&quot;https://gith
      
    
    </summary>
    
    
      <category term="ftp,k8s" scheme="https://bamboox.online/categories/ftp-k8s/"/>
    
    
      <category term="ftp" scheme="https://bamboox.online/tags/ftp/"/>
    
  </entry>
  
  <entry>
    <title>go mod 私有仓库搭建</title>
    <link href="https://bamboox.online/2019/11/01/go-mod-goproxy/"/>
    <id>https://bamboox.online/2019/11/01/go-mod-goproxy/</id>
    <published>2019-11-01T21:39:50.000Z</published>
    <updated>2019-11-24T15:43:34.817Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Go-包管理"><a href="#Go-包管理" class="headerlink" title="Go 包管理"></a>Go 包管理</h1><ol><li><code>godep</code></li><li><code>govendor</code></li></ol><p>都有各自的优缺点,本次着重介绍go mod</p><h1 id="Go-mod-使用"><a href="#Go-mod-使用" class="headerlink" title="Go mod 使用"></a>Go mod 使用</h1><p><code>go modules</code>是 golang 1.11 新加的特性。现在1.12 已经发布了，是时候用起来了。Modules官方定义为：</p><p>   模块是相关Go包的集合。modules是源代码交换和版本控制的单元。 go命令直接支持使用modules，包括记录和解析对其他模块的依赖性。modules替换旧的基于GOPATH的方法来指定在给定构建中使用哪些源文件。</p><p>Go mod 通过git获取github上项目资源，针对一些企业级项目很多情况下一些内部的SDK,TOOLS面临着无法直接require</p><h1 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h1><h2 id="利用-replace"><a href="#利用-replace" class="headerlink" title="利用 replace"></a>利用 replace</h2><ol><li>把需要引用的SDK导入到项目中，vendor或者其他目录</li><li>go.mod require gitlab.xxx.com/csi/common v0.0.0</li><li>go.mod replace gitlab.xxx.com/csi/common v0.0.0 -&gt; ./vendor/itlab.xxx.com/csi/common</li></ol><p>主要是利用gomod replace功能把本地文件引用进去，类似于java的maven导入本地jar包<br>不足： 多个项目需要重复执行</p><h1 id="goproxy利器"><a href="#goproxy利器" class="headerlink" title="goproxy利器"></a>goproxy利器</h1><p>开源项目<a href="https://github.com/goproxyio/goproxy" target="_blank" rel="noopener">https://github.com/goproxyio/goproxy</a></p><pre><code>                                         direct                      +----------------------------------&gt; private repo                      |                 match|pattern                      |                  +---+---+           +----------+go get  +-------&gt; |goproxy| +-------&gt; |goproxy.io| +---&gt; golang.org/x/net                  +-------+           +----------+                 router mode           proxy mode</code></pre><h2 id="搭建内网goproxy"><a href="#搭建内网goproxy" class="headerlink" title="搭建内网goproxy"></a>搭建内网goproxy</h2><h3 id="比较重要的2个参数"><a href="#比较重要的2个参数" class="headerlink" title="比较重要的2个参数"></a>比较重要的2个参数</h3><ol><li>proxy <a href="https://goproxy.io" target="_blank" rel="noopener">https://goproxy.io</a>  可以在配置一个goproxy可以用来获取被墙的package</li><li>exclude gitlab.*.com 将 <code>direct</code>走内网服务</li></ol><h3 id="发现代理gitlab还有些不足"><a href="#发现代理gitlab还有些不足" class="headerlink" title="发现代理gitlab还有些不足"></a>发现代理gitlab还有些不足</h3><p>我们需要在这个container配置gitlab <code>~/.ssh/id_rsa.pub</code><br>还有一个重要的配置就是git</p><h3 id="目的是将所有https转换出ssh"><a href="#目的是将所有https转换出ssh" class="headerlink" title="目的是将所有https转换出ssh"></a>目的是将所有https转换出ssh</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> config --global url.git@gitlab.xxxx.com:.insteadOf https://gitlab.xxxx.com/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="goproxy-修改"><a href="#goproxy-修改" class="headerlink" title="goproxy 修改"></a>goproxy 修改</h3><p>goproxy默认不支持 ssh</p><p>只需要修改dockerfile即可</p><p><a href="https://github.com/goproxyio/goproxy/blob/master/Dockerfile#L12" target="_blank" rel="noopener">https://github.com/goproxyio/goproxy/blob/master/Dockerfile#L12</a></p><pre><code>FROM golang:alpine AS buildRUN apk add --no-cache -U make git mercurial subversion bzr fossilCOPY . /src/goproxyRUN cd /src/goproxy &amp;&amp;\    export CGO_ENABLED=0 &amp;&amp;\    makeFROM golang:alpineRUN apk add --no-cache -U git mercurial subversion bzr fossil openssh-client #加入openssh-clientCOPY --from=build /src/goproxy/bin/goproxy /goproxyVOLUME /goEXPOSE 8081ENTRYPOINT [&quot;/goproxy&quot;]CMD []</code></pre><h3 id="重新编译"><a href="#重新编译" class="headerlink" title="重新编译"></a>重新编译</h3><p>docker build -t registry.cn-hangzhou.aliyuncs.com/bamboo/goproxy:1.0  .</p><h3 id="启动goproxy"><a href="#启动goproxy" class="headerlink" title="启动goproxy"></a>启动goproxy</h3><pre><code>docker run -d -p80:8081 -v /root/.ssh/:/root/.ssh \ registry.cn-hangzhou.aliyuncs.com/bamboo/goproxy:1.0  \ -proxy https://goproxy.io  -exclude &quot;gitlab.*.com&quot;</code></pre><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>go get -u -v gitlab.xxx.com/csi/common</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>Q: goprpxy无法代理gitlab<br>A: 进入容器内部执行</p><pre><code>go env -w GOPROXY=https://goproxy.cn,directgo env -w GOPRIVATE=gitlab.*.com</code></pre><p>Q: goprpxy还是不能获取被墙的package<br>A: 检查go env</p><pre><code>$ echo $GOPROXYhttps://goproxy.io$ echo $GO111MODULEon不符合就 export 设置一下</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://segmentfault.com/a/1190000018536993" target="_blank" rel="noopener">https://segmentfault.com/a/1190000018536993</a></li><li><a href="https://github.com/golang/go/wiki/Modules" target="_blank" rel="noopener">https://github.com/golang/go/wiki/Modules</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Go-包管理&quot;&gt;&lt;a href=&quot;#Go-包管理&quot; class=&quot;headerlink&quot; title=&quot;Go 包管理&quot;&gt;&lt;/a&gt;Go 包管理&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;code&gt;godep&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;govendor&lt;/code
      
    
    </summary>
    
    
      <category term="go,proxy,gomod,gitlab" scheme="https://bamboox.online/categories/go-proxy-gomod-gitlab/"/>
    
    
      <category term="go" scheme="https://bamboox.online/tags/go/"/>
    
  </entry>
  
  <entry>
    <title>K8S日志库源码分析：klog</title>
    <link href="https://bamboox.online/2019/10/01/k8s-klog/"/>
    <id>https://bamboox.online/2019/10/01/k8s-klog/</id>
    <published>2019-10-01T22:49:50.000Z</published>
    <updated>2020-03-28T17:52:42.638Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/kubernetes/klog/" target="_blank" rel="noopener">klog</a>是著名google开源C++日志库<a href="https://github.com/google/glog" target="_blank" rel="noopener">glog</a>的golang版本，具有轻量级、简单、稳定和高效等特性</p><h1 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h1><p>主要有以下特点：</p><ul><li>支持四种日志等级INFO &lt; WARING &lt; ERROR &lt; FATAL，不支持DEBUG等级。</li><li>每个日志等级对应一个日志文件，低等级的日志文件中除了包含该等级的日志，还会包含高等级的日志。</li><li>日志文件可以根据大小切割，但是不能根据日期切割。</li><li>日志文件名称格式：program.host.userName.log.log_level.date-time.pid，不可自定义。</li><li>固定日志输出格式：Lmmdd hh:mm:ss.uuuuuu threadid file:line] msg…，不可自定义。</li><li>程序开始时必须调用flag.Parse()解析命令行参数，退出时必须调用glog.Flush()确保将缓存区日志输出。</li></ul><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>Example：</p><pre class="line-numbers language-go"><code class="language-go"><span class="token keyword">package</span> main<span class="token keyword">import</span> <span class="token punctuation">(</span>    <span class="token string">"flag"</span>    <span class="token string">"fmt"</span>    <span class="token string">"os"</span>    <span class="token string">"k8s.io/klog"</span><span class="token punctuation">)</span><span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    klog<span class="token punctuation">.</span><span class="token function">InitFlags</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//Init the command-line flags.</span>    flag<span class="token punctuation">.</span><span class="token function">Parse</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Will be ignored as the program has exited in Fatal().</span>    <span class="token keyword">defer</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        fmt<span class="token punctuation">.</span><span class="token function">Println</span><span class="token punctuation">(</span><span class="token string">"Message in defer"</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Flushes all pending log I/O.</span>    <span class="token keyword">defer</span> klog<span class="token punctuation">.</span><span class="token function">Flush</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// The temp folder for log files when --log_dir is not set.</span>    fmt<span class="token punctuation">.</span><span class="token function">Printf</span><span class="token punctuation">(</span><span class="token string">"Temp folder for log files: %s\n"</span><span class="token punctuation">,</span> os<span class="token punctuation">.</span><span class="token function">TempDir</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    klog<span class="token punctuation">.</span><span class="token function">Info</span><span class="token punctuation">(</span><span class="token string">"Info"</span><span class="token punctuation">)</span>    klog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Info</span><span class="token punctuation">(</span><span class="token string">"L1 info"</span><span class="token punctuation">)</span>    klog<span class="token punctuation">.</span><span class="token function">Error</span><span class="token punctuation">(</span><span class="token string">"Error"</span><span class="token punctuation">)</span>    klog<span class="token punctuation">.</span><span class="token function">Fatal</span><span class="token punctuation">(</span><span class="token string">"Fatal"</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Will be ignored as the program has exited in Fatal().</span>    klog<span class="token punctuation">.</span><span class="token function">Error</span><span class="token punctuation">(</span><span class="token string">"Error after Fatal"</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Output</p><pre class="line-numbers language-shell"><code class="language-shell">$ go run klog.go  -logtostderr=false                                                                                                                                                                                                                      1 ↵Temp folder for log files: /tmpE1030 15:13:03.257539    5821 klog.go:30] ErrorF1030 15:13:03.257736    5821 klog.go:31] Fatalgoroutine 1 [running]:k8s.io/klog.stacks(0xc00008c200, 0xc0000d2000, 0x30, 0x40)        /home/bamboo/test/go/pkg/mod/k8s.io/klog@v1.0.0/klog.go:875 +0xb8k8s.io/klog.(*loggingT).output(0x5b5fc0, 0xc000000003, 0xc0000c4000, 0x59c9eb, 0x7, 0x1f, 0x0)        /home/bamboo/test/go/pkg/mod/k8s.io/klog@v1.0.0/klog.go:826 +0x330k8s.io/klog.(*loggingT).printDepth(0x5b5fc0, 0xc000000003, 0x1, 0xc0000cbf00, 0x1, 0x1)        /home/bamboo/test/go/pkg/mod/k8s.io/klog@v1.0.0/klog.go:698 +0x129k8s.io/klog.(*loggingT).print(...)        /home/bamboo/test/go/pkg/mod/k8s.io/klog@v1.0.0/klog.go:689k8s.io/klog.Fatal(...)        /home/bamboo/test/go/pkg/mod/k8s.io/klog@v1.0.0/klog.go:1256main.main()        /home/bamboo/test/go/src/bamboo/test/klog.go:31 +0x326exit status 255<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Usage</p><pre class="line-numbers language-shell"><code class="language-shell"> $ go run klog.go -h                                                                                                                                                                                                                                       1 ↵Usage of /tmp/go-build023011031/b001/exe/klog:  -add_dir_header        If true, adds the file directory to the header 如果为true，则将文件目录添加到标题中  -alsologtostderr         log to standard error as well as files  同时输出到os.Stderr和log files   -log_backtrace_at value         when logging hits line file:N, emit a stack trace 当日志长度超过定义的行数时，忽略堆栈信息。  -log_dir string        If non-empty, write log files in this directory  指定log files的目录，默认是os.TempDir()   -log_file string         If non-empty, use this log file 指定log files的文件名，如果是空安排日志级别分别创建日志文件，并且创建软连  -log_file_max_size uint          Defines the maximum size a log file can grow to. Unit is megabytes. If the value is 0, the maximum file size is unlimited. (default 1800) 日志文件大小单位MB  -logtostderr        log to standard error instead of files (default true) 输出日志到标准错误控制台，不输出到文件。  -skip_headers        If true, avoid header prefixes in the log messages 如果为true，请在日志消息中避免标题前缀  -skip_log_headers        If true, avoid headers when opening log files 如果为true，则在打开日志文件时避免标题  -stderrthreshold value         logs at or above this threshold go to stderr (default 2)  大于等于该severity的log，会输出到os.Stderr   -v value         number for the log level verbosity  设置vLog的等级   -vmodule value        comma-separated list of pattern=N settings for file-filtered logging 定输出日志的模块，格式如下：pattern=N，使用逗号分隔。exit status 2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Log files输出到默认的临时目录（/tmp）下。在标准输出上只能看到Info Error和Fatal log，是因为默认的<code>--v</code>为0。</p><p>需要注意的是， <code>-logtostderr=true</code> 调用glog.Fatal(“Fatal”)，程序会输出所有goroutine的堆栈信息，然后调用os.Exit()退出程序。所以，其前面的defer代码以及后面的代码，都不会执行。</p><h1 id="日志输出到文件配置："><a href="#日志输出到文件配置：" class="headerlink" title="日志输出到文件配置："></a>日志输出到文件配置：</h1><pre class="line-numbers language-shell"><code class="language-shell">- --v=5- --logtostderr=false- --log_dir=/xxx/xxx- --log_file=/xx/xx/xx.log- --stderrthreshold=1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h1><p>klog的代码非常简单，总共代码行数1.4K左右，分两个文件： <code>klog_file.go</code> <code>klog.go</code></p><ul><li>klog.go：主要实现log等级定义、输出以及vlog。</li><li>klog_file.go：主要实现日志文件目录和各等级日志文件的创建。</li></ul><h2 id="Log-Levels-Definition"><a href="#Log-Levels-Definition" class="headerlink" title="Log Levels Definition"></a>Log Levels Definition</h2><pre class="line-numbers language-go"><code class="language-go"><span class="token comment" spellcheck="true">// severity identifies the sort of log: info, warning etc. It also implements</span><span class="token comment" spellcheck="true">// the flag.Value interface. The -stderrthreshold flag is of type severity and</span><span class="token comment" spellcheck="true">// should be modified only through the flag.Value interface. The values match</span><span class="token comment" spellcheck="true">// the corresponding constants in C++.</span><span class="token keyword">type</span> severity <span class="token builtin">int32</span> <span class="token comment" spellcheck="true">// sync/atomic int32</span><span class="token comment" spellcheck="true">// These constants identify the log levels in order of increasing severity.</span><span class="token comment" spellcheck="true">// A message written to a high-severity log file is also written to each</span><span class="token comment" spellcheck="true">// lower-severity log file.</span><span class="token keyword">const</span> <span class="token punctuation">(</span>    infoLog severity <span class="token operator">=</span> <span class="token boolean">iota</span>    warningLog    errorLog    fatalLog    numSeverity <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token keyword">const</span> severityChar <span class="token operator">=</span> <span class="token string">"IWEF"</span><span class="token keyword">var</span> severityName <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">string</span><span class="token punctuation">{</span>    infoLog<span class="token punctuation">:</span>    <span class="token string">"INFO"</span><span class="token punctuation">,</span>    warningLog<span class="token punctuation">:</span> <span class="token string">"WARNING"</span><span class="token punctuation">,</span>    errorLog<span class="token punctuation">:</span>   <span class="token string">"ERROR"</span><span class="token punctuation">,</span>    fatalLog<span class="token punctuation">:</span>   <span class="token string">"FATAL"</span><span class="token punctuation">,</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Flush-Daemon"><a href="#Flush-Daemon" class="headerlink" title="Flush Daemon"></a>Flush Daemon</h2><p>klog在初始化的时候，会定义一些命令行参数，同时启动flush守护进程。Flush守护进程会间隔5s周期性地flush缓冲区中的log。</p><pre class="line-numbers language-go"><code class="language-go"><span class="token keyword">const</span> flushInterval <span class="token operator">=</span> <span class="token number">5</span> <span class="token operator">*</span> time<span class="token punctuation">.</span>Second<span class="token comment" spellcheck="true">// flushDaemon periodically flushes the log file buffers.</span><span class="token keyword">func</span> <span class="token punctuation">(</span>l <span class="token operator">*</span>loggingT<span class="token punctuation">)</span> <span class="token function">flushDaemon</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">for</span> <span class="token keyword">range</span> time<span class="token punctuation">.</span><span class="token function">NewTicker</span><span class="token punctuation">(</span>flushInterval<span class="token punctuation">)</span><span class="token punctuation">.</span>C <span class="token punctuation">{</span>        l<span class="token punctuation">.</span><span class="token function">lockAndFlushAll</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Log输出原理"><a href="#Log输出原理" class="headerlink" title="Log输出原理"></a>Log输出原理</h2><p>所有的log都支持多种输出模式，例如，Info<a href="">f|ln|Depth</a>，最终都是调用output()来输出到log files或者Stderr。</p><p><code>Info()</code>与<code>Infoln()</code>没有区别，因为glog为了保证每行只有一条log记录，会主动check末尾是否有换行符，如果没有的话，会自动加上。 <code>InfoDepth()</code>提供的<code>depth</code>参数，用来指定log信息中source file number来自的堆栈的深度。当<code>depth</code>为0时，就等价于<code>Info()</code>。 由于<code>depth</code>的设置很难有一个明确的参考标准，因此<code>InfoDepth()</code>不常用。</p><pre class="line-numbers language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>l <span class="token operator">*</span>loggingT<span class="token punctuation">)</span> <span class="token function">println</span><span class="token punctuation">(</span>s severity<span class="token punctuation">,</span> args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    buf<span class="token punctuation">,</span> file<span class="token punctuation">,</span> line <span class="token operator">:=</span> l<span class="token punctuation">.</span><span class="token function">header</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Fprintln</span><span class="token punctuation">(</span>buf<span class="token punctuation">,</span> args<span class="token operator">...</span><span class="token punctuation">)</span>    l<span class="token punctuation">.</span><span class="token function">output</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> buf<span class="token punctuation">,</span> file<span class="token punctuation">,</span> line<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>l <span class="token operator">*</span>loggingT<span class="token punctuation">)</span> <span class="token function">print</span><span class="token punctuation">(</span>s severity<span class="token punctuation">,</span> args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    l<span class="token punctuation">.</span><span class="token function">printDepth</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> args<span class="token operator">...</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>l <span class="token operator">*</span>loggingT<span class="token punctuation">)</span> <span class="token function">printDepth</span><span class="token punctuation">(</span>s severity<span class="token punctuation">,</span> depth <span class="token builtin">int</span><span class="token punctuation">,</span> args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    buf<span class="token punctuation">,</span> file<span class="token punctuation">,</span> line <span class="token operator">:=</span> l<span class="token punctuation">.</span><span class="token function">header</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> depth<span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Fprint</span><span class="token punctuation">(</span>buf<span class="token punctuation">,</span> args<span class="token operator">...</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> buf<span class="token punctuation">.</span><span class="token function">Bytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span>buf<span class="token punctuation">.</span><span class="token function">Len</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">'\n'</span> <span class="token punctuation">{</span>        buf<span class="token punctuation">.</span><span class="token function">WriteByte</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    l<span class="token punctuation">.</span><span class="token function">output</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> buf<span class="token punctuation">,</span> file<span class="token punctuation">,</span> line<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>l <span class="token operator">*</span>loggingT<span class="token punctuation">)</span> <span class="token function">printf</span><span class="token punctuation">(</span>s severity<span class="token punctuation">,</span> format <span class="token builtin">string</span><span class="token punctuation">,</span> args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    buf<span class="token punctuation">,</span> file<span class="token punctuation">,</span> line <span class="token operator">:=</span> l<span class="token punctuation">.</span><span class="token function">header</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Fprintf</span><span class="token punctuation">(</span>buf<span class="token punctuation">,</span> format<span class="token punctuation">,</span> args<span class="token operator">...</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> buf<span class="token punctuation">.</span><span class="token function">Bytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span>buf<span class="token punctuation">.</span><span class="token function">Len</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token string">'\n'</span> <span class="token punctuation">{</span>        buf<span class="token punctuation">.</span><span class="token function">WriteByte</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    l<span class="token punctuation">.</span><span class="token function">output</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> buf<span class="token punctuation">,</span> file<span class="token punctuation">,</span> line<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token operator">...</span><span class="token operator">...</span><span class="token comment" spellcheck="true">// Info logs to the INFO log.</span><span class="token comment" spellcheck="true">// Arguments are handled in the manner of fmt.Print; a newline is appended if missing.</span><span class="token keyword">func</span> <span class="token function">Info</span><span class="token punctuation">(</span>args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    logging<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span>infoLog<span class="token punctuation">,</span> args<span class="token operator">...</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// InfoDepth acts as Info but uses depth to determine which call frame to log.</span><span class="token comment" spellcheck="true">// InfoDepth(0, "msg") is the same as Info("msg").</span><span class="token keyword">func</span> <span class="token function">InfoDepth</span><span class="token punctuation">(</span>depth <span class="token builtin">int</span><span class="token punctuation">,</span> args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    logging<span class="token punctuation">.</span><span class="token function">printDepth</span><span class="token punctuation">(</span>infoLog<span class="token punctuation">,</span> depth<span class="token punctuation">,</span> args<span class="token operator">...</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// Infoln logs to the INFO log.</span><span class="token comment" spellcheck="true">// Arguments are handled in the manner of fmt.Println; a newline is appended if missing.</span><span class="token keyword">func</span> <span class="token function">Infoln</span><span class="token punctuation">(</span>args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    logging<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>infoLog<span class="token punctuation">,</span> args<span class="token operator">...</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// Infof logs to the INFO log.</span><span class="token comment" spellcheck="true">// Arguments are handled in the manner of fmt.Printf; a newline is appended if missing.</span><span class="token keyword">func</span> <span class="token function">Infof</span><span class="token punctuation">(</span>format <span class="token builtin">string</span><span class="token punctuation">,</span> args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    logging<span class="token punctuation">.</span><span class="token function">printf</span><span class="token punctuation">(</span>infoLog<span class="token punctuation">,</span> format<span class="token punctuation">,</span> args<span class="token operator">...</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>output()</code>在输出log的整个过程中都会加锁，以防止写冲突。每次输出log时都会check是否已调用<code>flag.Parse()</code>。  </p><p>如果没有调用就直接将log输出到Stderr，同时在其前面提示ERROR: logging before flag.Parse: 的错误。  </p><p>如果已经调用就会根据命令行参数来决定输出行为：如果设置–toStderr=true，就只会输出到Stderr  </p><p>如果设置<code>--alsoToStderr=true</code>，且输出log level大于或等于<code>--stderrThreshold</code>的话， 输出到log file的同时也会输出到Stderr  </p><p><code>stderrThreshold</code>的默认值是<code>ERROR</code> </p><p>klog还有另外一个很赞的功能就是，遇到Fatal log会在自动退出程序，并在退出前将所有goroutine的堆栈信息输出，方便排错。因此，在程序需要异常退出的时候，直接调用Fatal<a href="">f|ln|Depth</a>，应该成为一种标准做法。</p><pre class="line-numbers language-go"><code class="language-go"><span class="token comment" spellcheck="true">// output writes the data to the log files and releases the buffer.</span><span class="token keyword">func</span> <span class="token punctuation">(</span>l <span class="token operator">*</span>loggingT<span class="token punctuation">)</span> <span class="token function">output</span><span class="token punctuation">(</span>s severity<span class="token punctuation">,</span> buf <span class="token operator">*</span>buffer<span class="token punctuation">,</span> file <span class="token builtin">string</span><span class="token punctuation">,</span> line <span class="token builtin">int</span><span class="token punctuation">,</span> alsoToStderr <span class="token builtin">bool</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    l<span class="token punctuation">.</span>mu<span class="token punctuation">.</span><span class="token function">Lock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> l<span class="token punctuation">.</span>traceLocation<span class="token punctuation">.</span><span class="token function">isSet</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> l<span class="token punctuation">.</span>traceLocation<span class="token punctuation">.</span><span class="token function">match</span><span class="token punctuation">(</span>file<span class="token punctuation">,</span> line<span class="token punctuation">)</span> <span class="token punctuation">{</span>            buf<span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span><span class="token function">stacks</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    data <span class="token operator">:=</span> buf<span class="token punctuation">.</span><span class="token function">Bytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token operator">!</span>flag<span class="token punctuation">.</span><span class="token function">Parsed</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        os<span class="token punctuation">.</span>Stderr<span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token function">byte</span><span class="token punctuation">(</span><span class="token string">"ERROR: logging before flag.Parse: "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        os<span class="token punctuation">.</span>Stderr<span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> l<span class="token punctuation">.</span>toStderr <span class="token punctuation">{</span>        os<span class="token punctuation">.</span>Stderr<span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> alsoToStderr <span class="token operator">||</span> l<span class="token punctuation">.</span>alsoToStderr <span class="token operator">||</span> s <span class="token operator">>=</span> l<span class="token punctuation">.</span>stderrThreshold<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            os<span class="token punctuation">.</span>Stderr<span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span> l<span class="token punctuation">.</span>file<span class="token punctuation">[</span>s<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> err <span class="token operator">:=</span> l<span class="token punctuation">.</span><span class="token function">createFiles</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>                os<span class="token punctuation">.</span>Stderr<span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// Make sure the message appears somewhere.</span>                l<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>err<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">switch</span> s <span class="token punctuation">{</span>        <span class="token keyword">case</span> fatalLog<span class="token punctuation">:</span>            l<span class="token punctuation">.</span>file<span class="token punctuation">[</span>fatalLog<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>            <span class="token keyword">fallthrough</span>        <span class="token keyword">case</span> errorLog<span class="token punctuation">:</span>            l<span class="token punctuation">.</span>file<span class="token punctuation">[</span>errorLog<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>            <span class="token keyword">fallthrough</span>        <span class="token keyword">case</span> warningLog<span class="token punctuation">:</span>            l<span class="token punctuation">.</span>file<span class="token punctuation">[</span>warningLog<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>            <span class="token keyword">fallthrough</span>        <span class="token keyword">case</span> infoLog<span class="token punctuation">:</span>            l<span class="token punctuation">.</span>file<span class="token punctuation">[</span>infoLog<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> s <span class="token operator">==</span> fatalLog <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// If we got here via Exit rather than Fatal, print no stacks.</span>        <span class="token keyword">if</span> atomic<span class="token punctuation">.</span><span class="token function">LoadUint32</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>fatalNoStacks<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span> <span class="token punctuation">{</span>            l<span class="token punctuation">.</span>mu<span class="token punctuation">.</span><span class="token function">Unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token function">timeoutFlush</span><span class="token punctuation">(</span><span class="token number">10</span> <span class="token operator">*</span> time<span class="token punctuation">.</span>Second<span class="token punctuation">)</span>            os<span class="token punctuation">.</span><span class="token function">Exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// Dump all goroutine stacks before exiting.</span>        <span class="token comment" spellcheck="true">// First, make sure we see the trace for the current goroutine on standard error.</span>        <span class="token comment" spellcheck="true">// If -logtostderr has been specified, the loop below will do that anyway</span>        <span class="token comment" spellcheck="true">// as the first stack in the full dump.</span>        <span class="token keyword">if</span> <span class="token operator">!</span>l<span class="token punctuation">.</span>toStderr <span class="token punctuation">{</span>            os<span class="token punctuation">.</span>Stderr<span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span><span class="token function">stacks</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// Write the stack trace for all goroutines to the files.</span>        trace <span class="token operator">:=</span> <span class="token function">stacks</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>        logExitFunc <span class="token operator">=</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span> <span class="token comment" spellcheck="true">// If we get a write error, we'll still exit below.</span>        <span class="token keyword">for</span> log <span class="token operator">:=</span> fatalLog<span class="token punctuation">;</span> log <span class="token operator">>=</span> infoLog<span class="token punctuation">;</span> log<span class="token operator">--</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> f <span class="token operator">:=</span> l<span class="token punctuation">.</span>file<span class="token punctuation">[</span>log<span class="token punctuation">]</span><span class="token punctuation">;</span> f <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">// Can be nil if -logtostderr is set.</span>                f<span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span>trace<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        l<span class="token punctuation">.</span>mu<span class="token punctuation">.</span><span class="token function">Unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token function">timeoutFlush</span><span class="token punctuation">(</span><span class="token number">10</span> <span class="token operator">*</span> time<span class="token punctuation">.</span>Second<span class="token punctuation">)</span>        os<span class="token punctuation">.</span><span class="token function">Exit</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// C++ uses -1, which is silly because it's anded with 255 anyway.</span>    <span class="token punctuation">}</span>    l<span class="token punctuation">.</span><span class="token function">putBuffer</span><span class="token punctuation">(</span>buf<span class="token punctuation">)</span>    l<span class="token punctuation">.</span>mu<span class="token punctuation">.</span><span class="token function">Unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> stats <span class="token operator">:=</span> severityStats<span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token punctuation">;</span> stats <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        atomic<span class="token punctuation">.</span><span class="token function">AddInt64</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>stats<span class="token punctuation">.</span>lines<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        atomic<span class="token punctuation">.</span><span class="token function">AddInt64</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>stats<span class="token punctuation">.</span>bytes<span class="token punctuation">,</span> <span class="token function">int64</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="vLog"><a href="#vLog" class="headerlink" title="vLog"></a>vLog</h2><p>vLog是用户自定义的log级别，与glog自带的log级别完全独立，使log等级控制更加丰富，灵活。 不过只提供<code>Info()</code>，<code>Infof()</code>和<code>Infoln()</code>三个方法，因此只能对infoLog进行更细粒度的等级划分，可以认为是补充DEBUG等级。</p><p>使用方法很简单，有如下两种等价形式。虽然第二种简短，不过第一种代价更低。</p><pre class="line-numbers language-go"><code class="language-go"><span class="token keyword">if</span> glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    glog<span class="token punctuation">.</span><span class="token function">Info</span><span class="token punctuation">(</span><span class="token string">"log this"</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// Equals</span>glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Info</span><span class="token punctuation">(</span><span class="token string">"log this"</span><span class="token punctuation">)</span><span class="token string">``</span>vLog的实现原理也很简单：<span class="token string">``</span>`<span class="token keyword">go</span><span class="token operator">/</span> Verbose is a boolean <span class="token keyword">type</span> that implements <span class="token function">Infof</span> <span class="token punctuation">(</span>like Printf<span class="token punctuation">)</span> etc<span class="token punctuation">.</span><span class="token comment" spellcheck="true">// See the documentation of V for more information.</span><span class="token keyword">type</span> Verbose <span class="token builtin">bool</span><span class="token keyword">func</span> <span class="token function">V</span><span class="token punctuation">(</span>level Level<span class="token punctuation">)</span> Verbose <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// Here is a cheap but safe test to see if V logging is enabled globally.</span>    <span class="token keyword">if</span> logging<span class="token punctuation">.</span>verbosity<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">>=</span> level <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token function">Verbose</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> atomic<span class="token punctuation">.</span><span class="token function">LoadInt32</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>logging<span class="token punctuation">.</span>filterLength<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span> <span class="token punctuation">{</span>        logging<span class="token punctuation">.</span>mu<span class="token punctuation">.</span><span class="token function">Lock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">defer</span> logging<span class="token punctuation">.</span>mu<span class="token punctuation">.</span><span class="token function">Unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> runtime<span class="token punctuation">.</span><span class="token function">Callers</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> logging<span class="token punctuation">.</span>pcs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> <span class="token function">Verbose</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>        v<span class="token punctuation">,</span> ok <span class="token operator">:=</span> logging<span class="token punctuation">.</span>vmap<span class="token punctuation">[</span>logging<span class="token punctuation">.</span>pcs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>        <span class="token keyword">if</span> <span class="token operator">!</span>ok <span class="token punctuation">{</span>            v <span class="token operator">=</span> logging<span class="token punctuation">.</span><span class="token function">setV</span><span class="token punctuation">(</span>logging<span class="token punctuation">.</span>pcs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> <span class="token function">Verbose</span><span class="token punctuation">(</span>v <span class="token operator">>=</span> level<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token function">Verbose</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// Info is equivalent to the global Info function, guarded by the value of v.</span><span class="token comment" spellcheck="true">// See the documentation of V for usage.</span><span class="token keyword">func</span> <span class="token punctuation">(</span>v Verbose<span class="token punctuation">)</span> <span class="token function">Info</span><span class="token punctuation">(</span>args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> v <span class="token punctuation">{</span>        logging<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span>infoLog<span class="token punctuation">,</span> args<span class="token operator">...</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// Infoln is equivalent to the global Infoln function, guarded by the value of v.</span><span class="token comment" spellcheck="true">// See the documentation of V for usage.</span><span class="token keyword">func</span> <span class="token punctuation">(</span>v Verbose<span class="token punctuation">)</span> <span class="token function">Infoln</span><span class="token punctuation">(</span>args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> v <span class="token punctuation">{</span>        logging<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>infoLog<span class="token punctuation">,</span> args<span class="token operator">...</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// Infof is equivalent to the global Infof function, guarded by the value of v.</span><span class="token comment" spellcheck="true">// See the documentation of V for usage.</span><span class="token keyword">func</span> <span class="token punctuation">(</span>v Verbose<span class="token punctuation">)</span> <span class="token function">Infof</span><span class="token punctuation">(</span>format <span class="token builtin">string</span><span class="token punctuation">,</span> args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> v <span class="token punctuation">{</span>        logging<span class="token punctuation">.</span><span class="token function">printf</span><span class="token punctuation">(</span>infoLog<span class="token punctuation">,</span> format<span class="token punctuation">,</span> args<span class="token operator">...</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="flag-Parse-问题"><a href="#flag-Parse-问题" class="headerlink" title="flag.Parse()问题"></a>flag.Parse()问题</h1><p>在引用klog的同事千万注意不能在引用glog，不然启动的时候会出错</p><pre class="line-numbers language-shell"><code class="language-shell">panic: /tmp/___go_build_klog_go flag redefined: log_dir<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://github.com/kubernetes/klog/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;klog&lt;/a&gt;是著名google开源C++日志库&lt;a href=&quot;https://github.com/google/
      
    
    </summary>
    
    
      <category term="kubernetes,klog" scheme="https://bamboox.online/categories/kubernetes-klog/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>k8s-csi 版本变化</title>
    <link href="https://bamboox.online/2019/08/03/k8s-15-cun-chu-04/"/>
    <id>https://bamboox.online/2019/08/03/k8s-15-cun-chu-04/</id>
    <published>2019-08-03T22:05:50.000Z</published>
    <updated>2019-11-19T15:40:25.014Z</updated>
    
    <content type="html"><![CDATA[<h1 id="kubernetes-csi-版本变化"><a href="#kubernetes-csi-版本变化" class="headerlink" title="kubernetes-csi 版本变化"></a>kubernetes-csi 版本变化</h1><p><a href="https://kubernetes-csi.github.io/docs/introduction.html" target="_blank" rel="noopener">原文链接</a></p><h2 id="接口定义"><a href="#接口定义" class="headerlink" title="接口定义"></a>接口定义</h2><p><a href="https://github.com/container-storage-interface/spec/blob/master/lib/go/csi/csi.pb.go" target="_blank" rel="noopener">grpc pb</a></p><h2 id="changelog"><a href="#changelog" class="headerlink" title="changelog"></a>changelog</h2><h3 id="Kubernetes-1-15"><a href="#Kubernetes-1-15" class="headerlink" title="Kubernetes 1.15"></a>Kubernetes 1.15</h3><ul><li>New features:<ul><li>Volume capacity usage metrics</li></ul></li><li>New alpha features:<ul><li>Volume cloning</li><li>Ephemeral local volumes</li><li>Resizing secrets</li></ul></li></ul><h2 id="sidecar-containers"><a href="#sidecar-containers" class="headerlink" title="sidecar-containers"></a>sidecar-containers</h2><h3 id="external-provisioner"><a href="#external-provisioner" class="headerlink" title="external-provisioner"></a>external-provisioner</h3><ul><li>相关源码<ul><li><a href="https://github.com/kubernetes-csi/external-provisioner" target="_blank" rel="noopener">https://github.com/kubernetes-csi/external-provisioner</a></li></ul></li><li>主要接口:<ul><li>ControllerCreateVolume</li><li>ControllerDeleteVolume</li><li>Probe</li><li>GetPluginInfo</li><li>GetPluginCapabilitiesRequest</li><li>ControllerGetCapabilities</li></ul></li></ul><h3 id="external-attacher"><a href="#external-attacher" class="headerlink" title="external-attacher"></a>external-attacher</h3><ul><li>相关源码<ul><li><a href="https://github.com/kubernetes-csi/external-attacher" target="_blank" rel="noopener">https://github.com/kubernetes-csi/external-attacher</a></li></ul></li><li>主要接口:<ul><li>ControllerPublish</li><li>ControllerUnpublish</li><li>Probe</li><li>GetPluginInfo</li><li>GetPluginCapabilitiesRequest</li><li>ControllerGetCapabilities</li></ul></li></ul><h3 id="external-snapshotter"><a href="#external-snapshotter" class="headerlink" title="external-snapshotter"></a>external-snapshotter</h3><p>Volume Snapshot &amp; Restore.</p><ul><li>相关源码<ul><li><a href="https://github.com/kubernetes-csi/external-snapshotter" target="_blank" rel="noopener">https://github.com/kubernetes-csi/external-snapshotter</a></li></ul></li></ul><h3 id="node-driver-registrar"><a href="#node-driver-registrar" class="headerlink" title="node-driver-registrar"></a>node-driver-registrar</h3><ul><li>相关源码<ul><li><a href="https://github.com/kubernetes-csi/node-driver-registrar" target="_blank" rel="noopener">https://github.com/kubernetes-csi/node-driver-registrar</a></li></ul></li></ul><p><del>### cluster-driver-registrar 废弃</del></p><h3 id="livenessprobe"><a href="#livenessprobe" class="headerlink" title="livenessprobe"></a>livenessprobe</h3><ul><li>相关源码<ul><li><a href="https://github.com/kubernetes-csi/livenessprobe" target="_blank" rel="noopener">https://github.com/kubernetes-csi/livenessprobe</a></li></ul></li></ul><h3 id="external-resizer"><a href="#external-resizer" class="headerlink" title="external-resizer"></a>external-resizer</h3><ul><li>相关源码<ul><li><a href="https://github.com/kubernetes-csi/external-resizer/" target="_blank" rel="noopener">https://github.com/kubernetes-csi/external-resizer/</a></li></ul></li></ul><h2 id="相关功能点待补充"><a href="#相关功能点待补充" class="headerlink" title="相关功能点待补充"></a>相关功能点待补充</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;kubernetes-csi-版本变化&quot;&gt;&lt;a href=&quot;#kubernetes-csi-版本变化&quot; class=&quot;headerlink&quot; title=&quot;kubernetes-csi 版本变化&quot;&gt;&lt;/a&gt;kubernetes-csi 版本变化&lt;/h1&gt;&lt;p&gt;&lt;a
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
      <category term="csi" scheme="https://bamboox.online/tags/csi/"/>
    
  </entry>
  
  <entry>
    <title>docker隔离的缺陷</title>
    <link href="https://bamboox.online/2019/03/03/docker-03-zi-yuan-ge-chi/"/>
    <id>https://bamboox.online/2019/03/03/docker-03-zi-yuan-ge-chi/</id>
    <published>2019-03-03T22:05:50.000Z</published>
    <updated>2019-11-19T15:40:25.010Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Linux-里面的-LXCFS-机制"><a href="#Linux-里面的-LXCFS-机制" class="headerlink" title="Linux 里面的 LXCFS 机制"></a>Linux 里面的 LXCFS 机制</h1><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>知道如何修复容器中的 top 指令以及 /proc 文件系统中的信息呢</p><p><a href="https://github.com/fabric8io-images/run-java-sh/blob/master/fish-pepper/run-java-sh/readme.md" target="_blank" rel="noopener">https://github.com/fabric8io-images/run-java-sh/blob/master/fish-pepper/run-java-sh/readme.md</a></p><h2 id="解决docker-run-java"><a href="#解决docker-run-java" class="headerlink" title="解决docker run java"></a>解决docker run java</h2><ol><li><p>-Xmx 设置最大堆大小</p><pre><code>JAVA_OPTIONS=&#39;-Xmx300m&#39;</code></pre></li><li><p>Fabric8</p></li></ol><p><a href="https://github.com/fabric8io-images/run-java-sh/tree/master/fish-pepper/run-java-sh" target="_blank" rel="noopener">https://github.com/fabric8io-images/run-java-sh/tree/master/fish-pepper/run-java-sh</a></p><ul><li>core_limit<pre><code>local cpu_period_file=&quot;/sys/fs/cgroup/cpu/cpu.cfs_period_us&quot;local cpu_quota_file=&quot;/sys/fs/cgroup/cpu/cpu.cfs_quota_us&quot;</code></pre></li><li>max_memory<pre><code>local mem_file=&quot;/sys/fs/cgroup/memory/memory.limit_in_bytes&quot;</code></pre></li></ul><p>…..</p><p>echo “-XX:ParallelGCThreads=${core_limit} “ <br>         “-XX:ConcGCThreads=${core_limit} “ <br>         “-Djava.util.concurrent.ForkJoinPool.common.parallelism=${core_limit} “ <br>         “-XX:CICompilerCount=$(ci_compiler_count $core_limit)”</p><pre><code>jvm参数详情[http://www.cnblogs.com/redcreen/archive/2011/05/04/2037057.html](http://www.cnblogs.com/redcreen/archive/2011/05/04/2037057.html)## 新版JDK对docker容器的支持### cpu limit即如果没有显式指定-XX:ParalllelGCThreads 或者 -XX:CICompilerCount, 那么JVM使用docker的cpu限制。如果docker有指定cpu limit，jvm参数也有指定-XX:ParalllelGCThreads 或者 -XX:CICompilerCount，那么以指定的参数为准。### memory limit在java8u131+及java9，需要加上-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap才能使得Xmx感知docker的memory limit。#### 查看参数默认值java9</code></pre><p>java -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions -XX:+PrintFlagsFinal<br>bool UseCGroupMemoryLimitForHeap              = false                               {experimental} {default}</p><pre><code>可以看到在java9，UseCGroupMemoryLimitForHeap参数还是实验性的，默认关闭。|参数/版本 |XX:+UseCGroupMemoryLimitForHeap|XX:ActiveProcessorCount|XX:+UseContainerSupport|    |---------|-------|--------|--------||java9    |experimental，默认false|    |无|    无||java10    |experimental，默认false|    |-1    |无||java11    |移除    |-1|    product，默认true|# LXCFS简介社区中常见的做法是利用 lxcfs来提供容器中的资源可见性。lxcfs 是一个开源的FUSE（用户态文件系统）实现来支持LXC容器，它也可以支持Docker容器。LXCFS通过用户态文件系统，在容器中提供下列 procfs 的文件。</code></pre><p>/proc/cpuinfo<br>/proc/diskstats<br>/proc/meminfo<br>/proc/stat<br>/proc/swaps<br>/proc/uptime</p><pre><code>比如，把宿主机的 /var/lib/lxcfs/proc/memoinfo 文件挂载到Docker容器的/proc/meminfo位置后。容器中进程读取相应文件内容时，LXCFS的FUSE实现会从容器对应的Cgroup中读取正确的内存限制。从而使得应用获得正确的资源约束设定。## 测试安装 lxcfs 的RPM包</code></pre><p>wget <a href="https://copr-be.cloud.fedoraproject.org/results/ganto/lxd/epel-7-x86_64/00486278-lxcfs/lxcfs-2.0.5-3.el7.centos.x86_64.rpm" target="_blank" rel="noopener">https://copr-be.cloud.fedoraproject.org/results/ganto/lxd/epel-7-x86_64/00486278-lxcfs/lxcfs-2.0.5-3.el7.centos.x86_64.rpm</a><br>yum install lxcfs-2.0.5-3.el7.centos.x86_64.rpm  </p><pre><code>启动 lxcfs</code></pre><p>lxcfs /var/lib/lxcfs &amp;  </p><pre><code>测试</code></pre><p>$docker run -it -m 256m <br>      -v /var/lib/lxcfs/proc/cpuinfo:/proc/cpuinfo:rw <br>      -v /var/lib/lxcfs/proc/diskstats:/proc/diskstats:rw <br>      -v /var/lib/lxcfs/proc/meminfo:/proc/meminfo:rw <br>      -v /var/lib/lxcfs/proc/stat:/proc/stat:rw <br>      -v /var/lib/lxcfs/proc/swaps:/proc/swaps:rw <br>      -v /var/lib/lxcfs/proc/uptime:/proc/uptime:rw <br>      ubuntu:16.04 /bin/bash</p><p>root@f4a2a01e61cd:/# free<br>              total        used        free      shared  buff/cache   available<br>Mem:         262144         708      261436        2364           0      261436<br>Swap:             0           0           0</p><pre><code>我们可以看到total的内存为256MB，配置已经生效。## K8s如何注入K8s 最小单元是pod一个pod 包含多个container思路：一个init container处理 lxcfs隔离一个业务container如果解决部署问题：0. 通过: Kubernetes提供了 Initializer 扩展机制，自动添加lxcfs container 1. 通过: MutatingAdmissionWebhookdemo：shttps://juejin.im/post/5ba3547ae51d450e425ec6a52. 或者： podpreset 就是一个预设一个pod模版然后提交pod 填充模版的的数据### demo</code></pre><p>apiVersion: settings.k8s.io/v1alpha1<br>kind: PodPreset<br>metadata:<br>  name: allow-database<br>spec:<br>  selector:<br>    matchLabels:<br>      role: frontend<br>  env:<br>    - name: DB_PORT<br>      value: “6379”<br>  volumeMounts:<br>    - mountPath: /cache<br>      name: cache-volume<br>  volumes:<br>    - name: cache-volume<br>      emptyDir: {}</p><pre><code></code></pre><p>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: website<br>  labels:<br>    app: website<br>    role: frontend<br>spec:<br>  containers:<br>    - name: website<br>      image: nginx<br>      ports:<br>        - containerPort: 80</p><pre><code>最后：</code></pre><p>apiVersion: settings.k8s.io/v1alpha1<br>kind: PodPreset<br>metadata:<br>  name: allow-database<br>spec:<br>  selector:<br>    matchLabels:<br>      role: frontend<br>  env:<br>    - name: DB_PORT<br>      value: “6379”<br>  volumeMounts:<br>    - mountPath: /cache<br>      name: cache-volume<br>  volumes:<br>    - name: cache-volume<br>      emptyDir: {}</p><p>```</p><p>详细 <a href="https://kubernetes.io/docs/concepts/workloads/pods/podpreset/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/workloads/pods/podpreset/</a></p><p><a href="https://yq.aliyun.com/articles/566208?spm=a2c4e.11153959.blogcont566208.18.3fb44193UJVlwG" target="_blank" rel="noopener">https://yq.aliyun.com/articles/566208?spm=a2c4e.11153959.blogcont566208.18.3fb44193UJVlwG</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Linux-里面的-LXCFS-机制&quot;&gt;&lt;a href=&quot;#Linux-里面的-LXCFS-机制&quot; class=&quot;headerlink&quot; title=&quot;Linux 里面的 LXCFS 机制&quot;&gt;&lt;/a&gt;Linux 里面的 LXCFS 机制&lt;/h1&gt;&lt;h2 id=&quot;&quot;
      
    
    </summary>
    
    
      <category term="docker" scheme="https://bamboox.online/categories/docker/"/>
    
    
      <category term="docker" scheme="https://bamboox.online/tags/docker/"/>
    
      <category term="linux" scheme="https://bamboox.online/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Cgroup</title>
    <link href="https://bamboox.online/2019/03/02/docker-02-zi-yuan-ge-chi/"/>
    <id>https://bamboox.online/2019/03/02/docker-02-zi-yuan-ge-chi/</id>
    <published>2019-03-02T22:05:50.000Z</published>
    <updated>2019-11-19T15:40:25.010Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Linux-里面的-Cgroup-机制"><a href="#Linux-里面的-Cgroup-机制" class="headerlink" title="Linux 里面的 Cgroup 机制"></a>Linux 里面的 Cgroup 机制</h1><p>cgroup和namespace类似，也是将进程进行分组，但它的目的和namespace不一样，namespace是为了隔离进程组之间的资源，而cgroup是为了对一组进程进行统一的资源监控和限制。</p><p>cgroup分v1和v2两个版本，v1实现较早，功能比较多，但是由于它里面的功能都是零零散散的实现的，所以规划的不是很好，导致了一些使用和维护上的不便，v2的出现就是为了解决v1中这方面的问题，在最新的4.5内核中，cgroup v2声称已经可以用于生产环境了，但它所支持的功能还很有限，随着v2一起引入内核的还有cgroup namespace。v1和v2可以混合使用，但是这样会更复杂，所以一般没人会这样用。</p><h1 id="Cgroup-意义"><a href="#Cgroup-意义" class="headerlink" title="Cgroup 意义"></a>Cgroup 意义</h1><p>在Linux里，一直以来就有对进程进行分组的概念和需求，比如session group， progress group等，后来随着人们对这方面的需求越来越多，比如需要追踪一组进程的内存和IO使用情况等，于是出现了cgroup，用来统一将进程进行分组，并在分组的基础上对进程进行监控和资源控制管理等。</p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><pre><code>$ cat /proc/cgroups#subsys_name    hierarchy    num_cgroups    enabledcpuset    7    1    1cpu    3    70    1cpuacct    3    70    1blkio    10    70    1memory    2    112    1devices    8    70    1freezer    5    1    1net_cls    11    1    1perf_event    9    1    1net_prio    11    1    1hugetlb    4    1    1pids    6    71    1</code></pre><p>从左到右，字段的含义分别是：</p><ol><li>subsystem的名字</li><li>subsystem所关联到的cgroup树的ID，如果多个subsystem关联到同一颗cgroup树，那么他们的这个字段将一样，比如这里的cpu和cpuacct就一样，表示他们绑定到了同一颗树。如果出现下面的情况，这个字段将为0：</li></ol><ul><li>当前subsystem没有和任何cgroup树绑定</li><li>当前subsystem已经和cgroup v2的树绑定</li><li>当前subsystem没有被内核开启</li></ul><ol start="3"><li>subsystem所关联的cgroup树中进程组的个数，也即树上节点的个数</li><li>1表示开启，0表示没有被开启(可以通过设置内核的启动参数“cgroup_disable”来控制subsystem的开启).</li></ol><h1 id="如何使用cgroup"><a href="#如何使用cgroup" class="headerlink" title="如何使用cgroup"></a>如何使用cgroup</h1><p>利用cgroup </p><h2 id="创建子cgroup"><a href="#创建子cgroup" class="headerlink" title="创建子cgroup"></a>创建子cgroup</h2><p>在ubuntu下，systemd已经帮我们mount好了cpu子系统，我们只需要在相应的目录下创建子目录就可以了</p><pre><code>#从这里的输出可以看到，cpuset被挂载在了/sys/fs/cgroup/cpuset，#而cpu和cpuacct一起挂载到了/sys/fs/cgroup/cpu,cpuacct下面dev@ubuntu:~$ mount|grep cpucgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)#进入/sys/fs/cgroup/cpu,cpuacct并创建子cgroupdev@ubuntu:~$ cd /sys/fs/cgroup/cpu,cpuacctdev@ubuntu:/sys/fs/cgroup/cpu,cpuacct$ sudo mkdir testdev@ubuntu:/sys/fs/cgroup/cpu,cpuacct$ cd testdev@ubuntu:/sys/fs/cgroup/cpu,cpuacct/test$ lscgroup.clone_children  cpuacct.stat   cpuacct.usage_percpu  cpu.cfs_quota_us  cpu.stat           taskscgroup.procs           cpuacct.usage  cpu.cfs_period_us     cpu.shares        notify_on_release</code></pre><p>除了cgroup里面通用的cgroup.clone_children、tasks、cgroup.procs、notify_on_release这几个文件外，以cpuacct.开头的文件跟cpuacct子系统有关，我们这里只需要关注cpu.开头的文件。</p><h3 id="cpu-cfs-period-us-amp-cpu-cfs-quota-us"><a href="#cpu-cfs-period-us-amp-cpu-cfs-quota-us" class="headerlink" title="cpu.cfs_period_us &amp; cpu.cfs_quota_us"></a>cpu.cfs_period_us &amp; cpu.cfs_quota_us</h3><p>cfs_period_us用来配置时间周期长度，cfs_quota_us用来配置当前cgroup在设置的周期长度内所能使用的CPU时间数，两个文件配合起来设置CPU的使用上限。两个文件的单位都是微秒（us），cfs_period_us的取值范围为1毫秒（ms）到1秒（s），cfs_quota_us的取值大于1ms即可，如果cfs_quota_us的值为-1（默认值），表示不受cpu时间的限制。下面是几个例子：</p><pre><code>1.限制只能使用1个CPU（每250ms能使用250ms的CPU时间）    # echo 250000 &gt; cpu.cfs_quota_us /* quota = 250ms */    # echo 250000 &gt; cpu.cfs_period_us /* period = 250ms */2.限制使用2个CPU（内核）（每500ms能使用1000ms的CPU时间，即使用两个内核）    # echo 1000000 &gt; cpu.cfs_quota_us /* quota = 1000ms */    # echo 500000 &gt; cpu.cfs_period_us /* period = 500ms */3.限制使用1个CPU的20%（每50ms能使用10ms的CPU时间，即使用一个CPU核心的20%）    # echo 10000 &gt; cpu.cfs_quota_us /* quota = 10ms */    # echo 50000 &gt; cpu.cfs_period_us /* period = 50ms */</code></pre><h3 id="cpu-shares"><a href="#cpu-shares" class="headerlink" title="cpu.shares"></a>cpu.shares</h3><p>shares用来设置CPU的相对值，并且是针对所有的CPU（内核），默认值是1024，假如系统中有两个cgroup，分别是A和B，A的shares值是1024，B的shares值是512，那么A将获得1024/(1204+512)=66%的CPU资源，而B将获得33%的CPU资源。shares有两个特点：</p><ul><li>如果A不忙，没有使用到66%的CPU时间，那么剩余的CPU时间将会被系统分配给B，即B的CPU使用率可以超过33%</li><li>如果添加了一个新的cgroup C，且它的shares值是1024，那么A的限额变成了1024/(1204+512+1024)=40%，B的变成了20%</li></ul><p>从上面两个特点可以看出：</p><ul><li>在闲的时候，shares基本上不起作用，只有在CPU忙的时候起作用，这是一个优点。</li><li>由于shares是一个绝对值，需要和其它cgroup的值进行比较才能得到自己的相对限额，而在一个部署很多容器的机器上，cgroup的数量是变化的，所以这个限额也是变化的，自己设置了一个高的值，但别人可能设置了一个更高的值，所以这个功能没法精确的控制CPU使用率。</li></ul><h3 id="cpu-stat"><a href="#cpu-stat" class="headerlink" title="cpu.stat"></a>cpu.stat</h3><p>包含了下面三项统计结果</p><ul><li>nr_periods： 表示过去了多少个cpu.cfs_period_us里面配置的时间周期</li><li>nr_throttled： 在上面的这些周期中，有多少次是受到了限制（即cgroup中的进程在指定的时间周期中用光了它的配额）</li><li>throttled_time: cgroup中的进程被限制使用CPU持续了多长时间(纳秒)</li></ul><h4 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h4><p>这里以cfs_period_us &amp; cfs_quota_us为例，演示一下如何控制CPU的使用率。</p><pre><code>继续使用上面创建的子cgroup： test#设置只能使用1个cpu的20%的时间dev@ubuntu:/sys/fs/cgroup/cpu,cpuacct/test$ sudo sh -c &quot;echo 50000 &gt; cpu.cfs_period_us&quot;dev@ubuntu:/sys/fs/cgroup/cpu,cpuacct/test$ sudo sh -c &quot;echo 10000 &gt; cpu.cfs_quota_us&quot;#将当前bash加入到该cgroupdev@ubuntu:/sys/fs/cgroup/cpu,cpuacct/test$ echo $$5456dev@ubuntu:/sys/fs/cgroup/cpu,cpuacct/test$ sudo sh -c &quot;echo 5456 &gt; cgroup.procs&quot;#在bash中启动一个死循环来消耗cpu，正常情况下应该使用100%的cpu（即消耗一个内核）dev@ubuntu:/sys/fs/cgroup/cpu,cpuacct/test$ while :; do echo test &gt; /dev/null; done#--------------------------重新打开一个shell窗口----------------------#通过top命令可以看到5456的CPU使用率为20%左右，说明被限制住了#不过这时系统的%us+%sy在10%左右，那是因为我测试的机器上cpu是双核的，#所以系统整体的cpu使用率为10%左右dev@ubuntu:~$ topTasks: 139 total,   2 running, 137 sleeping,   0 stopped,   0 zombie%Cpu(s):  5.6 us,  6.2 sy,  0.0 ni, 88.2 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem :   499984 total,    15472 free,    81488 used,   403024 buff/cacheKiB Swap:        0 total,        0 free,        0 used.   383332 avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND 5456 dev       20   0   22640   5472   3524 R  20.3  1.1   0:04.62 bash#这时可以看到被限制的统计结果dev@ubuntu:~$ cat /sys/fs/cgroup/cpu,cpuacct/test/cpu.statnr_periods 1436nr_throttled 1304throttled_time 5154229183</code></pre><h1 id="chroot-与-Mount-namespace"><a href="#chroot-与-Mount-namespace" class="headerlink" title="chroot 与  Mount namespace"></a>chroot 与  Mount namespace</h1><h2 id="chroot"><a href="#chroot" class="headerlink" title="chroot"></a>chroot</h2><p>change root file system</p><p>在 Linux 操作系统里，有一个名为 chroot 的命令可以帮助你在 shell 中方便地完成这个工作。顾名思义，它的作用就是帮你“change root file system”，即改变进程的根目录到你指定的位置。它的用法也非常简单。</p><p>假设，我们现在有一个 $HOME/test 目录，想要把它作为一个 /bin/bash 进程的根目录。</p><p>首先，创建一个 test 目录和几个 lib 文件夹：</p><pre><code>$ mkdir -p $HOME/test$ mkdir -p $HOME/test/{bin,lib64,lib}</code></pre><p>然后，把 bash 命令拷贝到 test 目录对应的 bin 路径下：</p><pre><code>$ cp -v /bin/{bash,ls} $HOME/test/bin</code></pre><p>接下来，把 bash 命令需要的所有 so 文件，也拷贝到 test 目录对应的 lib 路径下。找到 so 文件可以用 ldd 命令：</p><pre><code>$ T=$HOME/test$ list=&quot;$(ldd /bin/ls | egrep -o &#39;/lib.*\.[0-9]&#39;)&quot;$ for i in $list; do cp -v &quot;$i&quot; &quot;${T}${i}&quot;; done</code></pre><p>最后，执行 chroot 命令，告诉操作系统，我们将使用 $HOME/test 目录作为 /bin/bash 进程的根目录：</p><pre><code>$ chroot $HOME/test /bin/bash</code></pre><p>这时，你如果执行 “ls /“，就会看到，它返回的都是 $HOME/test 目录下面的内容，而不是宿主机的内容。</p><p>更重要的是，对于被 chroot 的进程来说，它并不会感受到自己的根目录已经被“修改”成 $HOME/test 了。<br>这种视图被修改的原理，是不是跟我之前介绍的 Linux Namespace 很类似呢？<br>没错！<br>实际上，Mount Namespace 正是基于对 chroot 的不断改良才被发明出来的，它也是 Linux 操作系统里的第一个 Namespace。</p><h2 id="mount-namespace"><a href="#mount-namespace" class="headerlink" title="mount namespace"></a>mount namespace</h2><p>可以做到chroot的功能，而且比chroot更灵活。它属于内核名字空间的一部分。 mount namespace可以对系统真正根目录下的子目录做到共享、独享（也就是将拥有一个子目录的副本）等。 <a href="https://segmentfault.com/a/1190000006912742" target="_blank" rel="noopener">https://segmentfault.com/a/1190000006912742</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Linux-里面的-Cgroup-机制&quot;&gt;&lt;a href=&quot;#Linux-里面的-Cgroup-机制&quot; class=&quot;headerlink&quot; title=&quot;Linux 里面的 Cgroup 机制&quot;&gt;&lt;/a&gt;Linux 里面的 Cgroup 机制&lt;/h1&gt;&lt;p&gt;cg
      
    
    </summary>
    
    
      <category term="docker" scheme="https://bamboox.online/categories/docker/"/>
    
    
      <category term="docker" scheme="https://bamboox.online/tags/docker/"/>
    
      <category term="linux" scheme="https://bamboox.online/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>mosn</title>
    <link href="https://bamboox.online/2019/03/01/mesh-mosn-01/"/>
    <id>https://bamboox.online/2019/03/01/mesh-mosn-01/</id>
    <published>2019-03-01T22:49:50.000Z</published>
    <updated>2019-11-19T15:40:25.018Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="mosn" scheme="https://bamboox.online/categories/mosn/"/>
    
    
      <category term="mosn" scheme="https://bamboox.online/tags/mosn/"/>
    
  </entry>
  
  <entry>
    <title>Namespace</title>
    <link href="https://bamboox.online/2019/03/01/docker-01-zi-yuan-ge-chi/"/>
    <id>https://bamboox.online/2019/03/01/docker-01-zi-yuan-ge-chi/</id>
    <published>2019-03-01T22:05:50.000Z</published>
    <updated>2019-11-19T15:40:25.010Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Linux-里面的-Namespace-机制"><a href="#Linux-里面的-Namespace-机制" class="headerlink" title="Linux 里面的 Namespace 机制"></a>Linux 里面的 Namespace 机制</h1><p>Namespace是对全局系统资源的一种封装隔离，使得处于不同namespace的进程拥有独立的全局系统资源，改变一个namespace中的系统资源只会影响当前namespace里的进程，对其他namespace中的进程没有影响。</p><p>目前，Linux内核里面实现了7种不同类型的namespace。</p><table><thead><tr><th align="left">名称</th><th align="left">宏定义</th><th align="left">隔离内容</th></tr></thead><tbody><tr><td align="left">Cgroup</td><td align="left">CLONE_NEWCGROUP</td><td align="left">Cgroup root directory (since Linux 4.6)</td></tr><tr><td align="left">IPC</td><td align="left">CLONE_NEWIPC</td><td align="left">System V IPC, POSIX message queues (since Linux 2.6.19)</td></tr><tr><td align="left">Network</td><td align="left">CLONE_NEWNET</td><td align="left">Network devices, stacks, ports, etc. (since Linux 2.6.24)</td></tr><tr><td align="left">Mount</td><td align="left">CLONE_NEWNS</td><td align="left">Mount points (since Linux 2.4.19)</td></tr><tr><td align="left">PID</td><td align="left">CLONE_NEWPID</td><td align="left">Process IDs (since Linux 2.6.24)</td></tr><tr><td align="left">User</td><td align="left">CLONE_NEWUSER</td><td align="left">User and group IDs (started in Linux 2.6.23 and completed in Linux 3.8)</td></tr><tr><td align="left">UTS</td><td align="left">CLONE_NEWUTS</td><td align="left">Hostname and NIS domain name (since Linux 2.6.19)</td></tr></tbody></table><h2 id="查看进程所属的namespaces"><a href="#查看进程所属的namespaces" class="headerlink" title="查看进程所属的namespaces"></a>查看进程所属的namespaces</h2><p>系统中的每个进程都有/proc/[pid]/ns/这样一个目录，里面包含了这个进程所属namespace的信息，里面每个文件的描述符都可以用来作为setns函数(后面会介绍)的参数。</p><pre><code>#查看当前bash进程所属的namespacedev@ubuntu:~$ ls -l /proc/$$/ns     total 0lrwxrwxrwx 1 dev dev 0 7月 7 17:24 cgroup -&gt; cgroup:[4026531835] #(since Linux 4.6)lrwxrwxrwx 1 dev dev 0 7月 7 17:24 ipc -&gt; ipc:[4026531839]       #(since Linux 3.0)lrwxrwxrwx 1 dev dev 0 7月 7 17:24 mnt -&gt; mnt:[4026531840]       #(since Linux 3.8)lrwxrwxrwx 1 dev dev 0 7月 7 17:24 net -&gt; net:[4026531957]       #(since Linux 3.0)lrwxrwxrwx 1 dev dev 0 7月 7 17:24 pid -&gt; pid:[4026531836]       #(since Linux 3.8)lrwxrwxrwx 1 dev dev 0 7月 7 17:24 user -&gt; user:[4026531837]     #(since Linux 3.8)lrwxrwxrwx 1 dev dev 0 7月 7 17:24 uts -&gt; uts:[4026531838]       #(since Linux 3.0)</code></pre><p><strong>注意： 由于Cgroup namespace在4.6的内核中才实现</strong></p><h2 id="namespace相关的API"><a href="#namespace相关的API" class="headerlink" title="namespace相关的API"></a>namespace相关的API</h2><h3 id="clone"><a href="#clone" class="headerlink" title="clone"></a>clone</h3><p>创建一个新的进程并把他放到新的namespace中</p><pre><code>int clone(int (*child_func)(void *), void *child_stack            , int flags, void *arg);flags：     指定一个或者多个上面的CLONE_NEW*（当然也可以包含跟namespace无关的flags），     这样就会创建一个或多个新的不同类型的namespace，     并把新创建的子进程加入新创建的这些namespace中。</code></pre><h3 id="setns"><a href="#setns" class="headerlink" title="setns"></a>setns</h3><p>当前进程加入到已有的namespace中</p><pre><code>int setns(int fd, int nstype);fd：     指向/proc/[pid]/ns/目录里相应namespace对应的文件，    表示要加入哪个namespacenstype：    指定namespace的类型（上面的任意一个CLONE_NEW*）：    1. 如果当前进程不能根据fd得到它的类型，如fd由其他进程创建，    并通过UNIX domain socket传给当前进程，    那么就需要通过nstype来指定fd指向的namespace的类型    2. 如果进程能根据fd得到namespace类型，比如这个fd是由当前进程打开的，    那么nstype设置为0即可</code></pre><h3 id="unshare"><a href="#unshare" class="headerlink" title="unshare"></a>unshare</h3><p>使当前进程退出指定类型的namespace，并加入到新创建的namespace（相当于创建并加入新的namespace）</p><pre><code>int unshare(int flags);flags：    指定一个或者多个上面的CLONE_NEW*，    这样当前进程就退出了当前指定类型的namespace并加入到新创建的namespace</code></pre><p>clone和unshare的区别</p><ul><li>unshare是使当前进程加入新的namespace</li><li>clone是创建一个新的子进程，然后让子进程加入新的namespace，而当前进程保持不变</li></ul><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>当一个namespace中的所有进程都退出时，该namespace将会被销毁。当然还有其他方法让namespace一直存在，假设我们有一个进程号为1000的进程，以ipc namespace为例：</p><ul><li><p>通过mount –bind命令。例如mount –bind /proc/1000/ns/ipc /other/file，就算属于这个ipc namespace的所有进程都退出了，只要/other/file还在，这个ipc namespace就一直存在，其他进程就可以利用/other/file，通过setns函数加入到这个namespace</p></li><li><p>在其他namespace的进程中打开/proc/1000/ns/ipc文件，并一直持有这个文件描述符不关闭，以后就可以用setns函数加入这个namespace。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Linux-里面的-Namespace-机制&quot;&gt;&lt;a href=&quot;#Linux-里面的-Namespace-机制&quot; class=&quot;headerlink&quot; title=&quot;Linux 里面的 Namespace 机制&quot;&gt;&lt;/a&gt;Linux 里面的 Namespace 
      
    
    </summary>
    
    
      <category term="docker" scheme="https://bamboox.online/categories/docker/"/>
    
    
      <category term="docker" scheme="https://bamboox.online/tags/docker/"/>
    
      <category term="linux" scheme="https://bamboox.online/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>K8s 如何选择存储</title>
    <link href="https://bamboox.online/2019/02/22/k8s-15-cun-chu-03/"/>
    <id>https://bamboox.online/2019/02/22/k8s-15-cun-chu-03/</id>
    <published>2019-02-22T22:49:50.000Z</published>
    <updated>2019-11-19T15:40:25.014Z</updated>
    
    <content type="html"><![CDATA[<h1 id="如何选择存储"><a href="#如何选择存储" class="headerlink" title="如何选择存储"></a>如何选择存储</h1><h2 id="持久化数据的多种方式"><a href="#持久化数据的多种方式" class="headerlink" title="持久化数据的多种方式"></a>持久化数据的多种方式</h2><h3 id="Volume方式"><a href="#Volume方式" class="headerlink" title="Volume方式"></a>Volume方式</h3><p>awsElasticBlockStore是一个Volume类型。<br>你可以创建一个Pod，定义一个awsElasticBlockStore类型的volume，设置好volumeID，接着使用pod中存在的EBS volume。<br>该EBS volume在直接和Volume使用前必须已经存在。</p><h3 id="PV方式"><a href="#PV方式" class="headerlink" title="PV方式"></a>PV方式</h3><p>AWSElasticBlockStore还是一个PV类型。<br>所以你可以创建一个PV，用它来表示EBS volume（假设你有这样的权限），然后创建一个和它绑定的PVC卷。最后，令PVC作为volume，然后就可以在pod中使用它了。<br>和Volume方法类似，EBS volume在创建PV之前就必须存在。</p><h3 id="Provisioner方式"><a href="#Provisioner方式" class="headerlink" title="Provisioner方式"></a>Provisioner方式</h3><p>kubernetes.io/aws-ebs是一个Kubernetes中用于EBS的内置Provisioner。<br>你可以用Provisioner kubernetes.io/aws-ebs来创建一个Storage Class，通过Storage Class创建PVC。Kubernetes会自动为你创建相对应的PV。接下来指定PVC为volume就可以在pod中使用了。</p><h3 id="第三方方式"><a href="#第三方方式" class="headerlink" title="第三方方式"></a>第三方方式</h3><p>上面列出的都是Kubernetes内置选项，如果你不太满意的话，其实还有一些使用Flexvolume driver格式的第三方EBS实现，它们可以帮助你和Kubernetes连接起来。</p><p>如果Flexvolume不适合你，还可以使用具备同样功能的CSI drivers（为什么这么说？稍后会对此进行详细介绍）</p><p>VolumeClaimTemplate方式</p><p>如果你在使用StatefulSet，那么恭喜你！你现在有额外多了一种使用工作负载中EBS的方式——VolumeClaimTemple。</p><p>VolumeClaimTemple是StatefulSet规范属性，它为StatefulSet所创建的Pod提供了创建匹配PV和PVC的方式。这些PVC将通过Storage Class创建，这样当StatefulSet扩展时就可以自动创建它们。当StatefulSet缩小时，多余的PV/PVCs会保留在系统中。因此，当StatefulSet再一次扩展时，它们会再次作用于Kubernetes创建的新pods中。稍后我们会详细讲StatefulSet。</p><p>举个例子说明，假设你用replica 3创建了一个名为www的StatefulSet，并用它创建了名为data的VolumeClaimTemplate。Kubernetes会创建3个pods，分别起名www-0、www-1、www-2。Kubernetes还会创建PVC，其中www-data-0用于pod www-0，www-data-1给www-1，www-data-2给www-2。如果你把StatefulSet扩展到5，Kubernetes就会分别创建www-3、www-data-3、www-4、www-data-4。如果接着将StatefulSet降为1，www-1到www-4全都会删除，而www-data-1到www-data-4会保留在系统中。因此当你决定再次扩展到5的时候，pod www-1到www-4又回被创建出来，而PVC www-data-1仍然会服务于Pod www-1，www-data-2对应www-2，以此类推。这是因为StatefulSet中pod的身份在是stable的。使用StatefulSet时，名称和关系都是可以预测的。</p><p>VolumeClaimTemple对于像EBS和Longhorn这样的块存储解决方案非常重要。因为这些解决方案本质上是ReadWriteOnce，你不能在Pod之间共享它们。如果你有不止一个运行了持久化数据的pod，那么就无法顺利地进行部署。因此，VolumeClaimTemplate的出现为块存储解决方案提供了一种水平扩展Kubernetes工作负载的方式。</p><h1 id="如何在Volume、Persistent-Volume和Provisioner之间做出选择"><a href="#如何在Volume、Persistent-Volume和Provisioner之间做出选择" class="headerlink" title="如何在Volume、Persistent Volume和Provisioner之间做出选择"></a>如何在Volume、Persistent Volume和Provisioner之间做出选择</h1><p>可以看到，Volume、Persistent Volume以及Provisioner在一些细微的地方还是不一样的。</p><ol><li><p>Volume支持大部分的volume插件。</p><p> A.它是连接PVC和pod的唯一方法</p><p> B.它也是唯一一个支持Config Map、Secret、Downward API以及Projected的。这些所有都与Kubernetes API服务器密切相关。</p><p> C.它还是唯一一个支持EmptyDir的，EmptyDir可以自动给pod分配和清理临时volume。（注：早在2015年，Clayton Coleman就提出了一个关于支持EmptyDir的问题。这对于需要持久化储存但只有本地卷可用的工作负载，这非常有用。可是这一观点并没有得到太多的关注。没有scheduler的支持，这一目标在当时很难做到。而现在，在2018年，Kubernetes v1.11版本的Local Volume已经加入scheduler和PV的节点亲和支持（node affinity support），但是仍然没有EmptyDir PV。而且Local Volume特性并不是我所期望的那样，因为它并不具备在节点上使用新目录创建新卷的能力。因此，我编写了Local Path Provisioner，它利用scheduler和PV节点亲和更改，为工作负载提供动态的Host Path type PV。）</p></li><li><p>PV支持的插件是Provisioner支持的超集，因为Provisioner需要在工作负载使用它之前创建PV。但是，还有一些PV支持而Provisioner不支持的插件，比如Local Volume（正在进行修改中）。</p></li><li><p>还有两种类型Volume是不支持的。他们是两个最新的特性：CSI和Local Volume，现在还有一些正在进行的工作，会在之后把它们用于Volume。</p></li></ol><h3 id="在Volume、Persistent-Volume和Provisioner之间选择的准则"><a href="#在Volume、Persistent-Volume和Provisioner之间选择的准则" class="headerlink" title="在Volume、Persistent Volume和Provisioner之间选择的准则"></a>在Volume、Persistent Volume和Provisioner之间选择的准则</h3><p>那么用户到底应该选择哪种方式呢？</p><p>在我看来，用户们应该坚持一个原则：</p><p>在条件允许的情况下，选择Provisioner而不是Persistent Volume，接着再是Volume。</p><p>详细来说：</p><ol><li><p>对于Config Map、Downward API、Secret或者Projected，请使用Volume，因为PV不支持它们。</p></li><li><p>对于EmptyDir，直接使用Volume，或者使用Host Path来代替。</p></li><li><p>对于Host Path，通常是直接使用Volume，因为它绑定到一个特定的节点，并且节点之间它是同构的。<br>如果你想用异构的Host Path Volume，它在Kubernetes v1.11版之后才能使用，因为之前缺少对PV的节点亲和知识，使用v1.11+版本，你可以使用我的Local Path Provisioner创建带有节点亲和的Host Path PV：</p></li><li><p>对于其他的情况，除非你需要和现有的卷挂钩（这种情况下你应该使用PV），否则就使用Provisioner代替。有些Provisioner并不是内置的选项，但是你应该能在此链接（<a href="https://github.com/kubernetes-incubator/external-storage）或者供应商的官方仓库中找到它们。" target="_blank" rel="noopener">https://github.com/kubernetes-incubator/external-storage）或者供应商的官方仓库中找到它们。</a></p></li></ol><p>这个准则背后的原理很简单。在Kubernetes内部进行操作时，对象（PV）比属性（Volume）更容易管理，而且和手动创建PV相比，自动创建PV容易得多（Provisioner）。</p><p>不过这里有一个例外：如果你喜欢在Kubernetes外面进行存储，那么最好使用Volume，尽管使用这种方式需要用到另一组API进行创建/删除。此外，由于缺少VolumeClaimTemplate，会失去使用StatefulSet自动伸缩的能力。我不认为这是多数Kubernetes用户会选择的方式。</p><h2 id="为什么做同样的事会有这么多选项？"><a href="#为什么做同样的事会有这么多选项？" class="headerlink" title="为什么做同样的事会有这么多选项？"></a>为什么做同样的事会有这么多选项？</h2><p>当我开始研究Kubernetes存储时，首先想到的就是这个问题。由于缺乏一致性和直观性，Kubernetes存储看起来就像是事后才想到的。于是我试图研究这些设计决策背后的历史缘由，可是在2016之前都毫无收获。</p><p>最后，我倾向于相信这些是由于一些早期的设计造成的，这可能是为获取供应商支持的迫切需求，导致安排给Volume比原本更多的责任。在我看来，所有复制了PV的内置volume插件都不应该存在。</p><p>在研究历史的过程中，我发现在2016初发布的Kubernetes v1.2中，dynamic provisioning就已经成为了alpha特性。它需要两个发布版周期变成beta，在两个周期实现稳定，这都是非常合理的。</p><p>SIG Storage（它推动了Kubernetes存储开发）还进行了大量的工作，使用Provisioner和CSI将Volume插件从tree中移出来。我认为这是朝着更加一致、更加精简的系统迈出了一大步。</p><p>可另一方面，我也不认为这一大堆Volume类型会消失。这像是和硅谷非官方的格言唱反调：快速行动，打破常规。有时候，快速迭代的项目所遗留下来的设计，修改它们实在是太难了。我们只能和它们共处，在它们身边小心工作，不要用错误的方式调用它们。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;如何选择存储&quot;&gt;&lt;a href=&quot;#如何选择存储&quot; class=&quot;headerlink&quot; title=&quot;如何选择存储&quot;&gt;&lt;/a&gt;如何选择存储&lt;/h1&gt;&lt;h2 id=&quot;持久化数据的多种方式&quot;&gt;&lt;a href=&quot;#持久化数据的多种方式&quot; class=&quot;headerli
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>K8s PV、PVC、StorageClass</title>
    <link href="https://bamboox.online/2019/02/15/k8s-15-cun-chu-01/"/>
    <id>https://bamboox.online/2019/02/15/k8s-15-cun-chu-01/</id>
    <published>2019-02-15T22:49:50.000Z</published>
    <updated>2019-11-19T15:40:25.014Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PV、PVC、StorageClass"><a href="#PV、PVC、StorageClass" class="headerlink" title="PV、PVC、StorageClass"></a>PV、PVC、StorageClass</h1><h2 id="pv"><a href="#pv" class="headerlink" title="pv"></a>pv</h2><p>PV 描述的，是持久化存储数据卷。这个 API 对象主要定义的是一个持久化存储在宿主机上的目录，比如一个 NFS 的挂载目录。</p><p>通常情况下，PV 对象是由运维人员事先创建在 Kubernetes 集群里待用的。比如，运维人员可以定义这样一个 NFS 类型的 PV，如下所示：</p><pre><code>apiVersion: v1kind: PersistentVolumemetadata:  name: nfsspec:  storageClassName: manual  capacity:    storage: 1Gi  accessModes:    - ReadWriteMany  nfs:    server: 10.244.1.4    path: &quot;/&quot;</code></pre><h2 id="pvc"><a href="#pvc" class="headerlink" title="pvc"></a>pvc</h2><p>而PVC 描述的，则是 Pod 所希望使用的持久化存储的属性。比如，Volume 存储的大小、可读写权限等等。</p><p>PVC 对象通常由开发人员创建；或者以 PVC 模板的方式成为 StatefulSet 的一部分，然后由 StatefulSet 控制器负责创建带编号的 PVC。</p><p>比如，开发人员可以声明一个 1 GiB 大小的 PVC，如下所示：</p><pre><code>apiVersion: v1kind: PersistentVolumeClaimmetadata:  name: nfsspec:  accessModes:    - ReadWriteMany  storageClassName: manual  resources:    requests:      storage: 1Gi</code></pre><p>而用户创建的 PVC 要真正被容器使用起来，就必须先和某个符合条件的 PV 进行绑定。这里要检查的条件，包括两部分：</p><ol><li>第一个条件，当然是 PV 和 PVC 的 spec 字段。比如，PV 的存储（storage）大小，就必须满足 PVC 的要求。</li><li>第二个条件，则是 PV 和 PVC 的 storageClassName 字段必须一样。这个机制我会在本篇文章的最后一部分专门介绍。</li></ol><p>在成功地将 PVC 和 PV 进行绑定之后，Pod 就能够像使用 hostPath 等常规类型的 Volume 一样，在自己的 YAML 文件里声明使用这个 PVC 了，如下所示：</p><pre><code>apiVersion: v1kind: Podmetadata:  labels:    role: web-frontendspec:  containers:  - name: web    image: nginx    ports:      - name: web        containerPort: 80    volumeMounts:        - name: nfs          mountPath: &quot;/usr/share/nginx/html&quot;  volumes:  - name: nfs    persistentVolumeClaim:      claimName: nfs</code></pre><h2 id="StorageClass"><a href="#StorageClass" class="headerlink" title="StorageClass"></a>StorageClass</h2><p>StorageClass 的作用，则是充当 PV 的模板。并且，只有同属于一个 StorageClass 的 PV 和 PVC，才可以绑定在一起。</p><p>StorageClass 的另一个重要作用，是指定 PV 的 Provisioner（存储插件）。这时候，如果你的存储插件支持 Dynamic Provisioning 的话，Kubernetes 就可以自动为你创建 PV 了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;PV、PVC、StorageClass&quot;&gt;&lt;a href=&quot;#PV、PVC、StorageClass&quot; class=&quot;headerlink&quot; title=&quot;PV、PVC、StorageClass&quot;&gt;&lt;/a&gt;PV、PVC、StorageClass&lt;/h1&gt;&lt;h2 i
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>K8s CSI</title>
    <link href="https://bamboox.online/2019/02/15/k8s-15-cun-chu-02/"/>
    <id>https://bamboox.online/2019/02/15/k8s-15-cun-chu-02/</id>
    <published>2019-02-15T22:49:50.000Z</published>
    <updated>2019-11-19T15:40:25.014Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CSI开发"><a href="#CSI开发" class="headerlink" title="CSI开发"></a>CSI开发</h1><h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><p><img src="csi-01.png" alt=""></p><p>三个独立的外部组件（External Components），即：Driver Registrar、External Provisioner 和 External Attacher，对应的正是从 Kubernetes 项目里面剥离出来的那部分存储管理功能。</p><p>External Components 虽然是外部组件，但依然由 Kubernetes 社区来开发和维护。</p><h2 id="External-Components"><a href="#External-Components" class="headerlink" title="External Components"></a>External Components</h2><h3 id="Driver-Registrar"><a href="#Driver-Registrar" class="headerlink" title="Driver Registrar"></a>Driver Registrar</h3><p>负责将插件注册到 kubelet 里面（这可以类比为，将可执行文件放在插件目录下）。而在具体实现上，Driver Registrar 需要请求 CSI 插件的 Identity 服务来获取插件信息。</p><h3 id="External-Provisioner"><a href="#External-Provisioner" class="headerlink" title="External Provisioner"></a>External Provisioner</h3><p>负责的正是 Provision 阶段。在具体实现上，External Provisioner 监听（Watch）了 APIServer 里的 PVC 对象。当一个 PVC 被创建时，它就会调用 CSI Controller 的 CreateVolume 方法，为你创建对应 PV。</p><p>此外，如果你使用的存储是公有云提供的磁盘（或者块设备）的话，这一步就需要调用公有云（或者块设备服务）的 API 来创建这个 PV 所描述的磁盘（或者块设备）了。</p><p>不过，由于 CSI 插件是独立于 Kubernetes 之外的，所以在 CSI 的 API 里不会直接使用 Kubernetes 定义的 PV 类型，而是会自己定义一个单独的 Volume 类型。</p><h3 id="External-Attacher"><a href="#External-Attacher" class="headerlink" title="External Attacher"></a>External Attacher</h3><p>它监听了 APIServer 里 VolumeAttachment 对象的变化。VolumeAttachment 对象是 Kubernetes 确认一个 Volume 可以进入“Attach 阶段”的重要标志</p><p>一旦出现了 VolumeAttachment 对象，External Attacher 就会调用 CSI Controller 服务的 ControllerPublish 方法，完成它所对应的 Volume 的 Attach 阶段。</p><p><strong>注意</strong><br>Volume 的“Mount 阶段”，并不属于 External Components 的职责。当 kubelet 的 VolumeManagerReconciler 控制循环检查到它需要执行 Mount 操作的时候，会通过 pkg/volume/csi 包，直接调用 CSI Node 服务完成 Volume 的“Mount 阶段”。</p><p>在实际使用 CSI 插件的时候，我们会将这三个 External Components 作为 sidecar 容器和 CSI 插件放置在同一个 Pod 中。由于 External Components 对 CSI 插件的调用非常频繁，所以这种 sidecar 的部署方式非常高效。</p><h2 id="CSI-plugin"><a href="#CSI-plugin" class="headerlink" title="CSI plugin"></a>CSI plugin</h2><h3 id="CSI-Identity"><a href="#CSI-Identity" class="headerlink" title="CSI Identity"></a>CSI Identity</h3><p>负责对外暴露这个插件本身的信息</p><pre><code>service Identity {  // return the version and name of the plugin  rpc GetPluginInfo(GetPluginInfoRequest)    returns (GetPluginInfoResponse) {}  // reports whether the plugin has the ability of serving the Controller interface  rpc GetPluginCapabilities(GetPluginCapabilitiesRequest)    returns (GetPluginCapabilitiesResponse) {}  // called by the CO just to check whether the plugin is running or not  rpc Probe (ProbeRequest)    returns (ProbeResponse) {}}</code></pre><h3 id="CSI-Controller"><a href="#CSI-Controller" class="headerlink" title="CSI Controller"></a>CSI Controller</h3><p>定义的则是对 CSI Volume（对应 Kubernetes 里的 PV）的管理接口，比如：创建和删除 CSI Volume、对 CSI Volume 进行 Attach/Dettach（在 CSI 里，这个操作被叫作 Publish/Unpublish），以及对 CSI Volume 进行 Snapshot 等，它们的接口定义如下所示：</p><pre><code>service Controller {  // provisions a volume  rpc CreateVolume (CreateVolumeRequest)    returns (CreateVolumeResponse) {}  // deletes a previously provisioned volume  rpc DeleteVolume (DeleteVolumeRequest)    returns (DeleteVolumeResponse) {}  // make a volume available on some required node  rpc ControllerPublishVolume (ControllerPublishVolumeRequest)    returns (ControllerPublishVolumeResponse) {}  // make a volume un-available on some required node  rpc ControllerUnpublishVolume (ControllerUnpublishVolumeRequest)    returns (ControllerUnpublishVolumeResponse) {}  ...  // make a snapshot  rpc CreateSnapshot (CreateSnapshotRequest)    returns (CreateSnapshotResponse) {}  // Delete a given snapshot  rpc DeleteSnapshot (DeleteSnapshotRequest)    returns (DeleteSnapshotResponse) {}  ...}</code></pre><p>CSI Controller 服务里定义的这些操作有个共同特点，那就是它们都无需在宿主机上进行，而是属于 Kubernetes 里 Volume Controller 的逻辑，也就是属于 Master 节点的一部分。</p><p>CSI Controller 服务的实际调用者，并不是 Kubernetes（即：通过 pkg/volume/csi 发起 CSI 请求），而是 External Provisioner 和 External Attacher。这两个 External Components，分别通过监听 PVC 和 VolumeAttachement 对象，来跟 Kubernetes 进行协作。</p><h3 id="CSI-Node"><a href="#CSI-Node" class="headerlink" title="CSI Node"></a>CSI Node</h3><p>CSI Volume 需要在宿主机上执行的操作，都定义在了 CSI Node 服务里面，如下所示</p><pre><code>service Node {  // temporarily mount the volume to a staging path  rpc NodeStageVolume (NodeStageVolumeRequest)    returns (NodeStageVolumeResponse) {}  // unmount the volume from staging path  rpc NodeUnstageVolume (NodeUnstageVolumeRequest)    returns (NodeUnstageVolumeResponse) {}  // mount the volume from staging to target path  rpc NodePublishVolume (NodePublishVolumeRequest)    returns (NodePublishVolumeResponse) {}  // unmount the volume from staging path  rpc NodeUnpublishVolume (NodeUnpublishVolumeRequest)    returns (NodeUnpublishVolumeResponse) {}  // stats for the volume  rpc NodeGetVolumeStats (NodeGetVolumeStatsRequest)    returns (NodeGetVolumeStatsResponse) {}  ...  // Similar to NodeGetId  rpc NodeGetInfo (NodeGetInfoRequest)    returns (NodeGetInfoResponse) {}}</code></pre><p><strong>注意</strong><br>“Mount 阶段”在 CSI Node 里的接口，是由 NodeStageVolume 和 NodePublishVolume 两个接口共同实现的</p><p>CSI 的设计思想，把插件的职责从“两阶段处理”，扩展成了 Provision、Attach 和 Mount 三个阶段。其中，Provision 等价于“创建磁盘”，Attach 等价于“挂载磁盘到虚拟机”，Mount 等价于“将该磁盘格式化后，挂载在 Volume 的宿主机目录上”。</p><ul><li>当 AttachDetachController 需要进行“Attach”操作时（“Attach 阶段”），它实际上会执行到 pkg/volume/csi 目录中，创建一个 VolumeAttachment 对象，从而触发 External Attacher 调用 CSI Controller 服务的 ControllerPublishVolume 方法。</li><li>当 VolumeManagerReconciler 需要进行“Mount”操作时（“Mount 阶段”），它实际上也会执行到 pkg/volume/csi 目录中，直接向 CSI Node 服务发起调用 NodePublishVolume 方法的请求。</li></ul><h1 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h1><p>参考 <a href="https://github.com/AliyunContainerService/csi-plugin" target="_blank" rel="noopener">https://github.com/AliyunContainerService/csi-plugin</a></p><h3 id="定义-StorageClass"><a href="#定义-StorageClass" class="headerlink" title="定义 StorageClass"></a>定义 StorageClass</h3><pre><code>apiVersion: storage.k8s.io/v1kind: StorageClassmetadata:   name: csi-diskprovisioner: diskplugin.csi.alibabacloud.comparameters:    zoneId: cn-beijing-b    regionId: cn-beijing    fsType: ext4    type: cloud_ssd    readOnly: &quot;false&quot;reclaimPolicy: Delete</code></pre><p>有了这个 StorageClass，External Provisoner 就会为集群中新出现的 PVC 自动创建出 PV，然后调用 CSI 插件创建出这个 PV 对应的 Volume，这正是 CSI 体系中 Dynamic Provisioning 的实现方式。</p><p>这个 StorageClass 里唯一引人注意的，是 provisioner= diskplugin.csi.alibabacloud.com 这个字段。显然，这个字段告诉了 Kubernetes，请使用名叫  diskplugin.csi.alibabacloud.com 的 CSI 插件来为我处理这个 StorageClass 相关的所有操作。</p><p><img src="csi-02.jpg" alt=""></p><pre><code> else if drivername == TYPE_PLUGIN_DISK {        driver := disk.NewDriver(*nodeId, *endpoint)        driver.Run()    }.....func (disk *disk) Run() {    log.Infof(&quot;Starting csi-plugin Driver: %v version: %v&quot;, driverName, csiVersion)    s := csicommon.NewNonBlockingGRPCServer()    s.Start(disk.endpoint, disk.idServer, disk.controllerServer, disk.nodeServer)    s.Wait()}</code></pre><p>CSI Identity 服务中，最重要的接口是 GetPluginInfo，它返回的就是这个插件的名字和版本号，如下所示：<br><img src="csi-03.jpg" alt=""></p><pre><code>if ids.Driver.name == &quot;&quot; {        return nil, status.Error(codes.Unavailable, &quot;Driver name not configured&quot;)    }</code></pre><p>是由部署的时候配置的 –provisioner</p><pre><code> - name: csi-provisioner          image: registry.cn-hangzhou.aliyuncs.com/plugins/csi-provisioner:v1.0.0          args:            - &quot;--provisioner=diskplugin.csi.alibabacloud.com&quot;            - &quot;--csi-address=$(ADDRESS)&quot;            - &quot;--v=5&quot;</code></pre><p>GetPluginCapabilities 接口也很重要。这个接口返回的是这个 CSI 插件的“能力”</p><p>比如，当你编写的 CSI 插件不准备实现“Provision 阶段”和“Attach 阶段”（比如，一个最简单的 NFS 存储插件就不需要这两个阶段）时，你就可以通过这个接口返回：本插件不提供 CSI Controller 服务，即：没有 csi.PluginCapability_Service_CONTROLLER_SERVICE 这个“能力”。这样，Kubernetes 就知道这个信息了。</p><p>最后，CSI Identity 服务还提供了一个 Probe 接口。Kubernetes 会调用它来检查这个 CSI 插件是否正常工作。</p><p>一般情况下，我建议你在编写插件时给它设置一个 Ready 标志，当插件的 gRPC Server 停止的时候，把这个 Ready 标志设置为 false。或者，你可以在这里访问一下插件的端口，类似于健康检查的做法。</p><p>然后，我们要开始编写 CSI 插件的第二个服务，即 CSI Controller 服务了。它的代码实现，在 controller.go 文件里。</p><p>“Provision 阶段”对应的接口，是 CreateVolume 和 DeleteVolume，它们的调用者是 External Provisoner。以 CreateVolume 为例，它的主要逻辑如下所示</p><p><a href="https://github.com/AliyunContainerService/csi-plugin/blob/master/pkg/disk/controllerserver.go" target="_blank" rel="noopener">https://github.com/AliyunContainerService/csi-plugin/blob/master/pkg/disk/controllerserver.go</a></p><p>CreateVolume 需要做的操作，就是调用 Aliyun ECS 储服务的 API</p><p>而“Attach 阶段”对应的接口是 ControllerPublishVolume 和 ControllerUnpublishVolume，它们的调用者是 External Attacher。以 ControllerPublishVolume 为例，<br>是调用 ECS 的 API，将我们前面创建的存储卷，挂载到指定的ECS上</p><p>External Attacher 的工作原理，是监听（Watch）了一种名叫 VolumeAttachment 的 API 对象。这种 API 对象的主要字段如下所示：</p><pre><code>// VolumeAttachmentSpec is the specification of a VolumeAttachment request.type VolumeAttachmentSpec struct { // Attacher indicates the name of the volume driver that MUST handle this // request. This is the name returned by GetPluginName(). Attacher string // Source represents the volume that should be attached. Source VolumeAttachmentSource // The node that the volume should be attached to. NodeName string}</code></pre><p>而这个对象的生命周期，正是由 AttachDetachController 负责管理的</p><p>这个控制循环的职责，是不断检查 Pod 所对应的 PV，在它所绑定的宿主机上的挂载情况，从而决定是否需要对这个 PV 进行 Attach（或者 Dettach）操作。</p><p>而这个 Attach 操作，在 CSI 体系里，就是创建出上面这样一个 VolumeAttachment 对象。可以看到，Attach 操作所需的 PV 的名字（Source）、宿主机的名字（NodeName）、存储插件的名字（Attacher），都是这个 VolumeAttachment 对象的一部分。</p><p>而当 External Attacher 监听到这样的一个对象出现之后，就可以立即使用 VolumeAttachment 里的这些字段，封装成一个 gRPC 请求调用 CSI Controller 的 ControllerPublishVolume 方法。</p><p>CSI Node 服务对应的，是 Volume 管理流程里的“Mount 阶段”。它的代码实现，在 nodeserver.go文件里。</p><p><a href="https://sourcegraph.com/github.com/AliyunContainerService/csi-plugin@master/-/blob/pkg/disk/nodeserver.go" target="_blank" rel="noopener">https://sourcegraph.com/github.com/AliyunContainerService/csi-plugin@master/-/blob/pkg/disk/nodeserver.go</a></p><p>kubelet 的 VolumeManagerReconciler 控制循环会直接调用 CSI Node 服务来完成 Volume 的“Mount 阶段”。</p><p>不过，在具体的实现中，这个“Mount 阶段”的处理其实被细分成了 NodeStageVolume 和 NodePublishVolume 这两个接口</p><p>在 kubelet 的 VolumeManagerReconciler 控制循环中，这两步操作分别叫作MountDevice 和 SetUp。</p><ol><li>MountDevice 操作，就是直接调用了 CSI Node 服务里的 NodeStageVolume 接口。顾名思义，这个接口的作用，就是格式化 Volume 在宿主机上对应的存储设备，然后挂载到一个临时目录（Staging 目录）上。</li></ol><ol start="2"><li>SetUp 操作则会调用 CSI Node 服务的 NodePublishVolume 接口。有了上述对设备的预处理工作后，它的实现就非常简单了;<br>在这一步实现中，我们只需要做一步操作，即：将 Staging 目录，绑定挂载到 Volume 对应的宿主机目录上。</li></ol><p>对于文件系统类型的存储服务来说，比如 NFS 和 GlusterFS 等，它们并没有一个对应的磁盘“设备”存在于宿主机上，所以 kubelet 在 VolumeManagerReconciler 控制循环中，会跳过 MountDevice 操作而直接执行 SetUp 操作。所以对于它们来说，也就不需要实现 NodeStageVolume 接口了。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>不在赘述 可以直接参考</p><p><a href="https://github.com/AliyunContainerService/csi-plugin/tree/master/deploy/disk" target="_blank" rel="noopener">https://github.com/AliyunContainerService/csi-plugin/tree/master/deploy/disk</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;CSI开发&quot;&gt;&lt;a href=&quot;#CSI开发&quot; class=&quot;headerlink&quot; title=&quot;CSI开发&quot;&gt;&lt;/a&gt;CSI开发&lt;/h1&gt;&lt;h2 id=&quot;架构图&quot;&gt;&lt;a href=&quot;#架构图&quot; class=&quot;headerlink&quot; title=&quot;架构图&quot;&gt;&lt;/
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>K8s CNI</title>
    <link href="https://bamboox.online/2019/02/05/k8s-13-cni/"/>
    <id>https://bamboox.online/2019/02/05/k8s-13-cni/</id>
    <published>2019-02-05T22:49:50.000Z</published>
    <updated>2019-11-19T15:40:25.014Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CNI"><a href="#CNI" class="headerlink" title="CNI"></a>CNI</h1><p>CNI(container network interface)的目的在于定义一个标准的接口规范，使得kubernetes在增删POD的时候，能够按照规范向CNI实例提供标准的输入并获取标准的输出，再将输出作为kubernetes管理这个POD的网络的参考。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><pre><code>$ kubeadm init --pod-network-cidr=10.244.0.0/16$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml</code></pre><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>在安装完成后，你可以在宿主机的 /opt/cni/bin 目录下看到它们，如下所示：</p><pre><code>$ ls -al /opt/cni/bin/total 73088-rwxr-xr-x 1 root root  3890407 Aug 17  2017 bridge-rwxr-xr-x 1 root root  9921982 Aug 17  2017 dhcp-rwxr-xr-x 1 root root  2814104 Aug 17  2017 flannel-rwxr-xr-x 1 root root  2991965 Aug 17  2017 host-local-rwxr-xr-x 1 root root  3475802 Aug 17  2017 ipvlan-rwxr-xr-x 1 root root  3026388 Aug 17  2017 loopback-rwxr-xr-x 1 root root  3520724 Aug 17  2017 macvlan-rwxr-xr-x 1 root root  3470464 Aug 17  2017 portmap-rwxr-xr-x 1 root root  3877986 Aug 17  2017 ptp-rwxr-xr-x 1 root root  2605279 Aug 17  2017 sample-rwxr-xr-x 1 root root  2808402 Aug 17  2017 tuning-rwxr-xr-x 1 root root  3475750 Aug 17  2017 vlan</code></pre><p>这些 CNI 的基础可执行文件，按照功能可以分为三类:</p><ol><li><p>第一类，叫作 Main 插件，它是用来创建具体网络设备的二进制文件。比如，bridge（网桥设备）、ipvlan、loopback（lo 设备）、macvlan、ptp（Veth Pair 设备），以及 vlan。</p><p>Flannel、Weave 等项目，都属于“网桥”类型的 CNI 插件。所以在具体的实现中，它们往往会调用 bridge 这个二进制文件</p></li><li><p>第二类，叫作 IPAM（IP Address Management）插件，它是负责分配 IP 地址的二进制文件。比如，dhcp，这个文件会向 DHCP 服务器发起请求；host-local，则会使用预先配置的 IP 地址段来进行分配。</p></li><li><p>第三类，是由 CNI 社区维护的内置 CNI 插件。比如：flannel，就是专门为 Flannel 项目提供的 CNI 插件；tuning，是一个通过 sysctl 调整网络设备参数的二进制文件；portmap，是一个通过 iptables 配置端口映射的二进制文件；bandwidth，是一个使用 Token Bucket Filter (TBF) 来进行限流的二进制文件。</p></li></ol><p>从这些二进制文件中，我们可以看到，如果要实现一个给 Kubernetes 用的容器网络方案，其实需要做两部分工作，以 Flannel 项目为例：</p><p>首先，实现这个网络方案本身。这一部分需要编写的，其实就是 flanneld 进程里的主要逻辑。比如，创建和配置 flannel.1 设备、配置宿主机路由、配置 ARP 和 FDB 表里的信息等等。</p><p>然后，实现该网络方案对应的 CNI 插件。这一部分主要需要做的，就是配置 Infra 容器里面的网络栈，并把它连接在 CNI 网桥上。</p><p>CNI配置：</p><pre><code>$ cat /etc/cni/net.d/10-flannel.conflist {  &quot;name&quot;: &quot;cbr0&quot;,  &quot;plugins&quot;: [    {      &quot;type&quot;: &quot;flannel&quot;,      &quot;delegate&quot;: {        &quot;hairpinMode&quot;: true,        &quot;isDefaultGateway&quot;: true      }    },    {      &quot;type&quot;: &quot;portmap&quot;,      &quot;capabilities&quot;: {        &quot;portMappings&quot;: true      }    }  ]}</code></pre><p>在 Kubernetes 中，处理容器网络相关的逻辑并不会在 kubelet 主干代码里执行，而是会在具体的 CRI（Container Runtime Interface，容器运行时接口）实现里完成。对于 Docker 项目来说，它的 CRI 实现叫作 dockershim，你可以在 kubelet 的代码里找到它。</p><p>接下来 dockershim 会加载上述的 CNI 配置文件。</p><p>需要注意，Kubernetes 目前不支持多个 CNI 插件混用。如果你在 CNI 配置目录（/etc/cni/net.d）里放置了多个 CNI 配置文件的话，dockershim 只会加载按字母顺序排序的第一个插件。</p><p>但另一方面，CNI 允许你在一个 CNI 配置文件里，通过 plugins 字段，定义多个插件进行协作。</p><p>比如，在我们上面这个例子里，Flannel 项目就指定了 flannel 和 portmap 这两个插件。</p><p>dockershim 会把这个 CNI 配置文件加载起来，并且把列表里的第一个插件、也就是 flannel 插件，设置为默认插件。而在后面的执行过程中，flannel 和 portmap 插件会按照定义顺序被调用，从而依次完成“配置容器网络”和“配置端口映射”这两步操作。</p><p>当 kubelet 组件需要创建 Pod 的时候，它第一个创建的一定是 Infra 容器。所以在这一步，dockershim 就会先调用 Docker API 创建并启动 Infra 容器，紧接着执行一个叫作 SetUpPod 的方法。这个方法的作用就是：为 CNI 插件准备参数，然后调用 CNI 插件为 Infra 容器配置网络。</p><p>这里要调用的 CNI 插件，就是 /opt/cni/bin/flannel；而调用它所需要的参数，分为两部分。</p><p>第一部分，是由 dockershim 设置的一组 CNI 环境变量。</p><p>其中，最重要的环境变量参数叫作：CNI_COMMAND。它的取值只有两种：ADD 和 DEL。</p><p>这个 ADD 和 DEL 操作，就是 CNI 插件唯一需要实现的两个方法。</p><p>其中 ADD 操作的含义是：把容器添加到 CNI 网络里；DEL 操作的含义则是：把容器从 CNI 网络里移除掉。</p><p>而对于网桥类型的 CNI 插件来说，这两个操作意味着把容器以 Veth Pair 的方式“插”到 CNI 网桥上，或者从网桥上“拔”掉。</p><p>接下来，我以 ADD 操作为重点进行讲解。</p><p>CNI 的 ADD 操作需要的参数包括：容器里网卡的名字 eth0（CNI_IFNAME）、Pod 的 Network Namespace 文件的路径（CNI_NETNS）、容器的 ID（CNI_CONTAINERID）等。这些参数都属于上述环境变量里的内容。其中，Pod（Infra 容器）的 Network Namespace 文件的路径，即：/proc/&lt; 容器进程的 PID&gt;/ns/net</p><p>除此之外，在 CNI 环境变量里，还有一个叫作 CNI_ARGS 的参数。通过这个参数，CRI 实现（比如 dockershim）就可以以 Key-Value 的格式，传递自定义信息给网络插件。这是用户将来自定义 CNI 协议的一个重要方法。</p><p>第二部分，则是 dockershim 从 CNI 配置文件里加载到的、默认插件的配置信息。</p><p>这个配置信息在 CNI 中被叫作 Network Configuration，它的完整定义你可以参考这个文档。dockershim 会把 Network Configuration 以 JSON 数据的格式，通过标准输入（stdin）的方式传递给 Flannel CNI 插件。</p><p>而有了这两部分参数，Flannel CNI 插件实现 ADD 操作的过程就非常简单了。</p><p>不过，需要注意的是，Flannel 的 CNI 配置文件（ /etc/cni/net.d/10-flannel.conflist）里有这么一个字段，叫作 delegate：</p><pre><code>...     &quot;delegate&quot;: {        &quot;hairpinMode&quot;: true,        &quot;isDefaultGateway&quot;: true      }</code></pre><p>Delegate 字段的意思是，这个 CNI 插件并不会自己做事儿，而是会调用 Delegate 指定的某种 CNI 内置插件来完成。对于 Flannel 来说，它调用的 Delegate 插件，就是前面介绍到的 CNI bridge 插件。</p><p>所以说，dockershim 对 Flannel CNI 插件的调用，其实就是走了个过场。Flannel CNI 插件唯一需要做的，就是对 dockershim 传来的 Network Configuration 进行补充。比如，将 Delegate 的 Type 字段设置为 bridge，将 Delegate 的 IPAM 字段设置为 host-local 等。</p><p>经过 Flannel CNI 插件补充后的、完整的 Delegate 字段如下所示：</p><pre><code>{    &quot;hairpinMode&quot;:true,    &quot;ipMasq&quot;:false,    &quot;ipam&quot;:{        &quot;routes&quot;:[            {                &quot;dst&quot;:&quot;10.244.0.0/16&quot;            }        ],        &quot;subnet&quot;:&quot;10.244.1.0/24&quot;,        &quot;type&quot;:&quot;host-local&quot;    },    &quot;isDefaultGateway&quot;:true,    &quot;isGateway&quot;:true,    &quot;mtu&quot;:1410,    &quot;name&quot;:&quot;cbr0&quot;,    &quot;type&quot;:&quot;bridge&quot;}</code></pre><p>其中，ipam 字段里的信息，比如 10.244.1.0/24，读取自 Flannel 在宿主机上生成的 Flannel 配置文件，即：宿主机上的 /run/flannel/subnet.env 文件。</p><p>接下来，Flannel CNI 插件就会调用 CNI bridge 插件，也就是执行：/opt/cni/bin/bridge 二进制文件。</p><p>这一次，调用 CNI bridge 插件需要的两部分参数的第一部分、也就是 CNI 环境变量，并没有变化。所以，它里面的 CNI_COMMAND 参数的值还是“ADD”。</p><p>而第二部分 Network Configration，正是上面补充好的 Delegate 字段。Flannel CNI 插件会把 Delegate 字段的内容以标准输入（stdin）的方式传递给 CNI bridge 插件。</p><p>此外，Flannel CNI 插件还会把 Delegate 字段以 JSON 文件的方式，保存在 /var/lib/cni/flannel 目录下。这是为了给后面删除容器调用 DEL 操作时使用的。</p><p>有了这两部分参数，接下来 CNI bridge 插件就可以“代表”Flannel，进行“将容器加入到 CNI 网络里”这一步操作了。而这一部分内容，与容器 Network Namespace 密切相关，所以我要为你详细讲解一下。</p><p>首先，CNI bridge 插件会在宿主机上检查 CNI 网桥是否存在。如果没有的话，那就创建它。这相当于在宿主机上执行：</p><pre><code># 在宿主机上$ ip link add cni0 type bridge$ ip link set cni0 up</code></pre><p>接下来，CNI bridge 插件会通过 Infra 容器的 Network Namespace 文件，进入到这个 Network Namespace 里面，然后创建一对 Veth Pair 设备。</p><p>紧接着，它会把这个 Veth Pair 的其中一端，“移动”到宿主机上。这相当于在容器里执行如下所示的命令：</p><pre><code># 在容器里# 创建一对 Veth Pair 设备。其中一个叫作 eth0，另一个叫作 vethb4963f3$ ip link add eth0 type veth peer name vethb4963f3# 启动 eth0 设备$ ip link set eth0 up # 将 Veth Pair 设备的另一端（也就是 vethb4963f3 设备）放到宿主机（也就是 Host Namespace）里$ ip link set vethb4963f3 netns $HOST_NS# 通过 Host Namespace，启动宿主机上的 vethb4963f3 设备$ ip netns exec $HOST_NS ip link set vethb4963f3 up </code></pre><p>这样，vethb4963f3 就出现在了宿主机上，而且这个 Veth Pair 设备的另一端，就是容器里面的 eth0。</p><p>上述创建 Veth Pair 设备的操作，其实也可以先在宿主机上执行，然后再把该设备的一端放到容器的 Network Namespace 里，这个原理是一样的。</p><p>不过，CNI 插件之所以要“反着”来，是因为 CNI 里对 Namespace 操作函数的设计就是如此，如下所示：</p><pre><code>err := containerNS.Do(func(hostNS ns.NetNS) error {  ...  return nil})</code></pre><p>这个设计其实很容易理解。在编程时，容器的 Namespace 是可以直接通过 Namespace 文件拿到的；而 Host Namespace，则是一个隐含在上下文的参数。所以，像上面这样，先通过容器 Namespace 进入容器里面，然后再反向操作 Host Namespace，对于编程来说要更加方便。</p><p>接下来，CNI bridge 插件就可以把 vethb4963f3 设备连接在 CNI 网桥上。这相当于在宿主机上执行：</p><pre><code># 在宿主机上$ ip link set vethb4963f3 master cni0</code></pre><p>在将 vethb4963f3 设备连接在 CNI 网桥之后，CNI bridge 插件还会为它设置Hairpin Mode（发夹模式）。这是因为，在默认情况下，网桥设备是不允许一个数据包从一个端口进来后，再从这个端口发出去的。但是，它允许你为这个端口开启 Hairpin Mode，从而取消这个限制。</p><p>这个特性，主要用在容器需要通过NAT（即：端口映射）的方式，“自己访问自己”的场景下。</p><p>举个例子，比如我们执行 docker run -p 8080:80，就是在宿主机上通过 iptables 设置了一条DNAT（目的地址转换）转发规则。这条规则的作用是，当宿主机上的进程访问“&lt; 宿主机的 IP 地址 &gt;:8080”时，iptables 会把该请求直接转发到“&lt; 容器的 IP 地址 &gt;:80”上。也就是说，这个请求最终会经过 docker0 网桥进入容器里面。</p><p>但如果你是在容器里面访问宿主机的 8080 端口，那么这个容器里发出的 IP 包会经过 vethb4963f3 设备（端口）和 docker0 网桥，来到宿主机上。此时，根据上述 DNAT 规则，这个 IP 包又需要回到 docker0 网桥，并且还是通过 vethb4963f3 端口进入到容器里。所以，这种情况下，我们就需要开启 vethb4963f3 端口的 Hairpin Mode 了。</p><p>所以说，Flannel 插件要在 CNI 配置文件里声明 hairpinMode=true。这样，将来这个集群里的 Pod 才可以通过它自己的 Service 访问到自己。</p><p>接下来，CNI bridge 插件会调用 CNI ipam 插件，从 ipam.subnet 字段规定的网段里为容器分配一个可用的 IP 地址。然后，CNI bridge 插件就会把这个 IP 地址添加在容器的 eth0 网卡上，同时为容器设置默认路由。这相当于在容器里执行：</p><pre><code># 在容器里$ ip addr add 10.244.0.2/24 dev eth0$ ip route add default via 10.244.0.1 dev eth0</code></pre><p>最后，CNI bridge 插件会为 CNI 网桥添加 IP 地址。这相当于在宿主机上执行：</p><pre><code># 在宿主机上$ ip addr add 10.244.0.1/24 dev cni0</code></pre><p>在执行完上述操作之后，CNI 插件会把容器的 IP 地址等信息返回给 dockershim，然后被 kubelet 添加到 Pod 的 Status 字段。</p><p>至此，CNI 插件的 ADD 方法就宣告结束了。接下来的流程，就跟容器跨主机通信的过程完全一致了。</p><p>需要注意的是，对于非网桥类型的 CNI 插件，上述“将容器添加到 CNI 网络”的操作流程，以及网络方案本身的工作原理，就都不太一样了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;CNI&quot;&gt;&lt;a href=&quot;#CNI&quot; class=&quot;headerlink&quot; title=&quot;CNI&quot;&gt;&lt;/a&gt;CNI&lt;/h1&gt;&lt;p&gt;CNI(container network interface)的目的在于定义一个标准的接口规范，使得kubernetes在增删PO
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>K8s choosing-a-cni-provider</title>
    <link href="https://bamboox.online/2019/02/05/k8s-14-cni/"/>
    <id>https://bamboox.online/2019/02/05/k8s-14-cni/</id>
    <published>2019-02-05T22:49:50.000Z</published>
    <updated>2019-11-19T15:40:25.014Z</updated>
    
    <content type="html"><![CDATA[<h1 id="choosing-a-cni-provider"><a href="#choosing-a-cni-provider" class="headerlink" title="choosing-a-cni-provider"></a>choosing-a-cni-provider</h1><p>容器网络接口（CNI）是一个库定义，是Cloud Native Computing Foundation项目保护下的一组工具。有关更多信息，请访问他们的GitHub 项目。Kubernetes使用CNI作为网络提供商和Kubernetes网络之间的接口。</p><h2 id="Why-Use-CNI"><a href="#Why-Use-CNI" class="headerlink" title="Why Use CNI"></a>Why Use CNI</h2><p>Kubernetes默认网络提供商kubenet是一个简单的网络插件，可与各种云提供商合作。Kubenet是一个非常基本的网络提供商，基本是好的，但没有很多功能。此外，kubenet有许多局限性。例如，在AWS Cloud中运行kubenet时，您只能使用50个EC2实例。路由表用于配置Kubernetes节点之间的网络流量，每个VPC限制为50个条目。此外，无法在专用VPC中设置群集，因为该网络拓扑使用多个路由表。其他更高级的功能，如BGP，出口控制和网状网络，仅适用于不同的CNI提供商。</p><h2 id="Choosing-a-Provider"><a href="#Choosing-a-Provider" class="headerlink" title="Choosing a Provider"></a>Choosing a Provider</h2><p>Which CNI provider should I use?</p><h2 id="CNI-in-kops"><a href="#CNI-in-kops" class="headerlink" title="CNI in kops"></a>CNI in kops</h2><p>最后统计，除了kubenet之外，kops还支持七种不同的CNI提供商。有以下</p><ul><li>Calico</li><li>Canal (Flannel + Calico)</li><li>flannel</li><li>kopeio-vxlan</li><li>kube-router</li><li>romana</li><li>Weave Net</li></ul><p>任何这些CNI提供者都可以在没有kops的情况下使用。所有CNI提供程序都使用守护程序安装模型，其产品部署Kubernetes Daemonset。一旦K8s API服务器启动，只需使用kubectl在主服务器上安装提供程序。请参阅每个项目的具体文档。</p><h2 id="Summary-of-the-Providers"><a href="#Summary-of-the-Providers" class="headerlink" title="Summary of the Providers"></a>Summary of the Providers</h2><h3 id="Calico"><a href="#Calico" class="headerlink" title="Calico"></a>Calico</h3><p>Mike Stowe提供了Calico和Canal的摘要。</p><p>Calico使用纯L3方法提供简单，可扩展的网络。它支持在支持它的环境中的本机，未封装网络，包括AWS，AZ和其他在节点之间具有L2邻接的环境，或者在可以使用BGP与基础架构对等的部署中，例如内部部署。Calico还提供无状态IP-in-IP模式，如有必要，可在其他环境中使用。除了可扩展的网络，Project Calico还提供策略隔离，允许您使用高级入口和出口策略保护和管理您的微服务/容器基础架构。通过广泛的Kubernetes支持，您可以在Kubernetes 1.8+中管理您的策略。</p><h3 id="Canal"><a href="#Canal" class="headerlink" title="Canal"></a>Canal</h3><p>Canal是一家CNI提供商，为您提供最好的Flannel和Project Calico，提供简单，易用/开箱即用的VXLAN网络，同时还允许您利用Calico策略的策略隔离。</p><p>对于想要在利用他们可能已经使用的熟悉技术的同时启动和运行的任何人来说，此提供商都是一个解决方案</p><h3 id="flannel"><a href="#flannel" class="headerlink" title="flannel"></a>flannel</h3><p>flannel是一种简单易用的方法，可以配置为Kubernetes设计的layer3网络结构。没有外部数据库（使用Kubernetes API），简单的性能可以在VXLAN默认的任何地方工作，可以与Calico策略引擎（Canal）分层。哦，还有很多用户。</p><p>Coreco的商业Kubernetes产品Tectonic，使用flannel和来自Calico的Felix ，就像Canal一样。</p><h3 id="kopeio-networking"><a href="#kopeio-networking" class="headerlink" title="kopeio-networking"></a>kopeio-networking</h3><p>kopeio-networking提供Kubernetes第一个网络。它是专为Kubernetes而设计的，充分利用了Kubernetes API，因此比改装的替代品更简单，更可靠。VXLAN方法是最常用的模式（用于编织和法兰绒），但它也支持第2层（用于印花布），更多实验性支持GRE（替代IPIP）和IPSEC（用于安全）配置）。它通过非常简单的代码库完成所有这些工作</p><h3 id="kube-router"><a href="#kube-router" class="headerlink" title="kube-router"></a>kube-router</h3><p>Kube-router是专为Kubernetes打造的专用网络解决方案。它旨在提供操作简单性和性能。Kube-router提供pod网络解决方案，服务代理和网络策略实施器作为一体化解决方案，并设置了单个守护进程。Kuber-router使用Kubernetes本机功能，如注释，由kube-controller-manger分配pod CIDR。因此它不依赖于数据存储，也没有为节点的pod CIDR分配实现任何自定义解决方案。Kube-router也使用标准的CNI插件，因此需要任何额外的CNI插件。Kube-router建立在标准的Linux网络工具集和ipset，iptables，ipvs和lvs等技术之上。</p><h3 id="romana"><a href="#romana" class="headerlink" title="romana"></a>romana</h3><p>Romana为pod网络使用标准的第3层网络。Romana支持Kubernetes网络策略API，即使群集跨网络可用区域分割，也不需要覆盖。Romana支持各种网络拓扑，包括平面第2层和路由第3层网络。节点之间的路由在本地安装，必要时使用BGP或OSPF分发到网络设备。在AWS部署中，Romana将聚合路由安装到VPC路由表中以克服50节点限制。这使Romana可以跨HA集群的可用区域使用本机VPC网络。当前版本使用自己的etcd集群，但下一个版本可选择允许Kubernetes etcd集群用作数据存储。</p><h3 id="Weave-Net"><a href="#Weave-Net" class="headerlink" title="Weave Net"></a>Weave Net</h3><p>Weave Net支持覆盖网络，可以跨越不同的云网络配置，简化Kubernetes上运行的旧工作负载。例如，Weave支持多播，即使底层网络没有。Weave可以在AWS上运行时配置基础VPC网络并绕过覆盖。此提供程序形成可分区且最终一致的主机网状网络; 这意味着设置几乎为零配置，并且它不需要依赖Etcd。Weave支持加密和Kubernetes网络策略，确保网络级别具有安全性。</p><h2 id="GitHub-Stars"><a href="#GitHub-Stars" class="headerlink" title="GitHub Stars"></a>GitHub Stars</h2><p><img src="cni-github-03.png" alt=""></p><h2 id="GitHub-Contributors"><a href="#GitHub-Contributors" class="headerlink" title="GitHub Contributors"></a>GitHub Contributors</h2><p><img src="cni-github-01.png" alt=""></p><h2 id="GitHub-Forks"><a href="#GitHub-Forks" class="headerlink" title="GitHub Forks"></a>GitHub Forks</h2><p><img src="cni-github-02.png" alt=""></p><h2 id="Support-Matrix"><a href="#Support-Matrix" class="headerlink" title="Support Matrix"></a>Support Matrix</h2><p>|Provider    |Network Model|Route Distribution|Network Policies|Mesh|External Datastore|Encryption    Ingress/Egress Policies    |Commercial Support|<br>|———|———|———|———|———|———|———|———|———|<br>|Calico    |Layer 3    |Yes |    Yes |    Yes    |Etcd|    Yes|    Yes    |Yes|<br>|Canal    |Layer 2 vxlan| N/A|    Yes    |No|Etcd |No|    Yes|    No|<br>|flannel    |vxlan    |No    |No    |No|    None    |No    |No    |No|<br>|kopeio-networking    |Layer 2 vxlan |    N/A |    No|    No|    None|    Yes|    No|    No|<br>|kube-router    |Layer 3    |BGP    |Yes|    No|    No|    No|    No|    No|<br>|romana    |Layer 3    |OSPF    |Yes|    No    |Etcd    |No    |Yes    |Yes|<br>|Weave Net    |Layer 2 vxlan|    N/A    |Yes|    Yes    |No|    Yes    |Yes|    Yes|</p><ol><li>Calico和Canal包含一个直接连接到Kubernetes的功能，而不是使用Etcd。</li><li>kopeio CNI提供商有三种不同的组网方式：vlan，layer2，GRE和IPSEC。</li><li>kopie-network在IPSEC模式下提供加密，而不是默认的vxlan模式。</li><li>Weave Net可以在没有vxlan的AWS-VPC模式下运行，但在EC2中仅限于50个节点。</li><li>Weave Net没有开箱即用的出口规则。</li></ol><h3 id="Table-Details"><a href="#Table-Details" class="headerlink" title="Table Details"></a>Table Details</h3><ol><li>Network Model</li></ol><p>具有提供商的网络模型是封装网络（如VXLAN）或未封装的第2层网络。封装网络流量需要计算才能处理，因此理论上要慢一些。在我看来，大多数用例不会受到开销的影响。有关维基百科上的 VXLAN的更多信息 。</p><ol start="2"><li>Route Distribution</li></ol><p>对于第3层CNI提供商，路由分发是必要的。路由分配通常通过BGP进行。如果您计划构建跨网段分割的群集，则路由分发很适合使用CNI功能。它是一种外部网关协议，旨在在互联网上交换路由和可达性信息。BGP可以协助群集之间的pod到pod联网。</p><ol start="3"><li>Network Policies</li></ol><p><a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/services-networking/network-policies/</a></p><ol start="4"><li>Mesh Networking</li></ol><p>此功能允许Kubernetes集群之间的“Pod to Pod”网络。这项技术不是Kubernetes联合会，而是Pods之间的纯粹网络。</p><ol start="5"><li>Encyption</li></ol><p>加密网络控制平面，以便加密所有TCP和UDP流量。</p><ol start="6"><li>Ingress / Egress Policies</li></ol><p>网络策略是Kubernetes和Non-Kubernetes路由控制。例如，许多提供商将允许管理员阻止与169.254.169.254上的EC2实例元数据服务进行通信的pod。</p><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ul><li><a href="https://chrislovecnm.com/kubernetes/cni/choosing-a-cni-provider/" target="_blank" rel="noopener">https://chrislovecnm.com/kubernetes/cni/choosing-a-cni-provider/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;choosing-a-cni-provider&quot;&gt;&lt;a href=&quot;#choosing-a-cni-provider&quot; class=&quot;headerlink&quot; title=&quot;choosing-a-cni-provider&quot;&gt;&lt;/a&gt;choosing-a-cni-pr
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>K8s Flannel</title>
    <link href="https://bamboox.online/2019/02/04/k8s-12-flannel/"/>
    <id>https://bamboox.online/2019/02/04/k8s-12-flannel/</id>
    <published>2019-02-04T22:49:50.000Z</published>
    <updated>2019-11-19T15:40:25.010Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Flannel"><a href="#Flannel" class="headerlink" title="Flannel"></a>Flannel</h1><p>Flannel 项目是 CoreOS 公司主推的容器网络方案。事实上，Flannel 项目本身只是一个框架，提供容器网络功能的，是 Flannel 的后端实现。目前，Flannel 支持三种后端实现，分别是：</p><ul><li>VXLAN</li><li>host-gw</li><li>UDP</li></ul><h2 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h2><p>在这个例子中，有两台宿主机。</p><ul><li>宿主机 Node 1 上有一个容器 container-1，它的 IP 地址是 100.96.1.2，对应的 docker0 网桥的地址是：100.96.1.1/24。</li><li>宿主机 Node 2 上有一个容器 container-2，它的 IP 地址是 100.96.2.3，对应的 docker0 网桥的地址是：100.96.2.1/24。</li></ul><p>让 container-1 访问 container-2。<br>这种情况下，container-1 容器里的进程发起的 IP 包，其源地址就是 100.96.1.2，目的地址就是 100.96.2.3。由于目的地址 100.96.2.3 并不在 Node 1 的 docker0 网桥的网段里，所以这个 IP 包会被交给默认路由规则，通过容器的网关进入 docker0 网桥（如果是同一台宿主机上的容器间通信，走的是直连规则），从而出现在宿主机上。<br>这时候，这个 IP 包的下一个目的地，就取决于宿主机上的路由规则了。此时，Flannel 已经在宿主机上创建出了一系列的路由规则，以 Node 1 为例，如下所示：</p><pre><code># 在 Node 1 上$ ip routedefault via 10.168.0.1 dev eth0100.96.0.0/16 dev flannel0  proto kernel  scope link src 100.96.1.0100.96.1.0/24 dev docker0  proto kernel  scope link  src 100.96.1.110.168.0.0/24 dev eth0  proto kernel  scope link  src 10.168.0.2</code></pre><p>可以看到，由于 IP 包的目的地址是 100.96.2.3，它匹配不到本机 docker0 网桥对应的 100.96.1.0/24 网段，只能匹配到第二条、也就是 100.96.0.0/16 对应的这条路由规则，从而进入到一个叫作 flannel0 的设备中。</p><p>而这个 flannel0 设备的类型就比较有意思了：它是一个 TUN 设备（Tunnel 设备）。</p><p>在 Linux 中，TUN 设备是一种工作在三层（Network Layer）的虚拟网络设备。TUN 设备的功能非常简单，即：在操作系统内核和用户应用程序之间传递 IP 包。</p><p>以 flannel0 设备为例：</p><p>像上面提到的情况，当操作系统将一个 IP 包发送给 flannel0 设备之后，flannel0 就会把这个 IP 包，交给创建这个设备的应用程序，也就是 Flannel 进程。这是一个从内核态（Linux 操作系统）向用户态（Flannel 进程）的流动方向。</p><p>反之，如果 Flannel 进程向 flannel0 设备发送了一个 IP 包，那么这个 IP 包就会出现在宿主机网络栈中，然后根据宿主机的路由表进行下一步处理。这是一个从用户态向内核态的流动方向。</p><p>所以，当 IP 包从容器经过 docker0 出现在宿主机，然后又根据路由表进入 flannel0 设备后，宿主机上的 flanneld 进程（Flannel 项目在每个宿主机上的主进程），就会收到这个 IP 包。然后，flanneld 看到了这个 IP 包的目的地址，是 100.96.2.3，就把它发送给了 Node 2 宿主机。</p><p>等一下，flanneld 又是如何知道这个 IP 地址对应的容器，是运行在 Node 2 上的呢？</p><p>这里，就用到了 Flannel 项目里一个非常重要的概念：子网（Subnet）。</p><p>事实上，在由 Flannel 管理的容器网络里，一台宿主机上的所有容器，都属于该宿主机被分配的一个“子网”。在例子中，Node 1 的子网是 100.96.1.0/24，container-1 的 IP 地址是 100.96.1.2。Node 2 的子网是 100.96.2.0/24，container-2 的 IP 地址是 100.96.2.3。</p><p>而这些子网与宿主机的对应关系，正是保存在 Etcd 当中，如下所示：</p><pre><code>$ etcdctl ls /coreos.com/network/subnets/coreos.com/network/subnets/100.96.1.0-24/coreos.com/network/subnets/100.96.2.0-24/coreos.com/network/subnets/100.96.3.0-24</code></pre><p>所以，flanneld 进程在处理由 flannel0 传入的 IP 包时，就可以根据目的 IP 的地址（比如 100.96.2.3），匹配到对应的子网（比如 100.96.2.0/24），从 Etcd 中找到这个子网对应的宿主机的 IP 地址是 10.168.0.3，如下所示：</p><pre><code>$ etcdctl get /coreos.com/network/subnets/100.96.2.0-24{&quot;PublicIP&quot;:&quot;10.168.0.3&quot;}</code></pre><p>而对于 flanneld 来说，只要 Node 1 和 Node 2 是互通的，那么 flanneld 作为 Node 1 上的一个普通进程，就一定可以通过上述 IP 地址（10.168.0.3）访问到 Node 2，这没有任何问题。</p><p>所以说，flanneld 在收到 container-1 发给 container-2 的 IP 包之后，就会把这个 IP 包直接封装在一个 UDP 包里，然后发送给 Node 2。不难理解，这个 UDP 包的源地址，就是 flanneld 所在的 Node 1 的地址，而目的地址，则是 container-2 所在的宿主机 Node 2 的地址。</p><p>当然，这个请求得以完成的原因是，每台宿主机上的 flanneld，都监听着一个 8285 端口，所以 flanneld 只要把 UDP 包发往 Node 2 的 8285 端口即可。</p><p>通过这样一个普通的、宿主机之间的 UDP 通信，一个 UDP 包就从 Node 1 到达了 Node 2。而 Node 2 上监听 8285 端口的进程也是 flanneld，所以这时候，flanneld 就可以从这个 UDP 包里解析出封装在里面的、container-1 发来的原 IP 包。</p><p>而接下来 flanneld 的工作就非常简单了：flanneld 会直接把这个 IP 包发送给它所管理的 TUN 设备，即 flannel0 设备。</p><p>根据前面讲解的 TUN 设备的原理，这正是一个从用户态向内核态的流动方向（Flannel 进程向 TUN 设备发送数据包），所以 Linux 内核网络栈就会负责处理这个 IP 包，具体的处理方法，就是通过本机的路由表来寻找这个 IP 包的下一步流向。</p><p>而 Node 2 上的路由表，跟 Node 1 非常类似，如下所示：</p><pre><code># 在 Node 2 上$ ip routedefault via 10.168.0.1 dev eth0100.96.0.0/16 dev flannel0  proto kernel  scope link  src 100.96.2.0100.96.2.0/24 dev docker0  proto kernel  scope link  src 100.96.2.110.168.0.0/24 dev eth0  proto kernel  scope link  src 10.168.0.3</code></pre><p>docker0 网桥会扮演二层交换机的角色，将数据包发送给正确的端口，进而通过 Veth Pair 设备进入到 container-2 的 Network Namespace 里。</p><p>而 container-2 返回给 container-1 的数据包，则会经过与上述过程完全相反的路径回到 container-1 中。</p><p>需要注意的是，上述流程要正确工作还有一个重要的前提，那就是 docker0 网桥的地址范围必须是 Flannel 为宿主机分配的子网。这个很容易实现，以 Node 1 为例，你只需要给它上面的 Docker Daemon 启动时配置如下所示的 bip 参数即可：</p><pre><code>$ FLANNEL_SUBNET=100.96.1.1/24$ dockerd --bip=$FLANNEL_SUBNET ...</code></pre><p><img src="flannel-01.png" alt=""></p><p>Flannel UDP 模式提供的其实是一个三层的 Overlay 网络，即：它首先对发出端的 IP 包进行 UDP 封装，然后在接收端进行解封装拿到原始的 IP 包，进而把这个 IP 包转发给目标容器。这就好比，Flannel 在不同宿主机上的两个容器之间打通了一条“隧道”，使得这两个容器可以直接使用 IP 地址进行通信，而无需关心容器和宿主机的分布情况。</p><p>上述 UDP 模式有严重的性能问题，所以已经被废弃了</p><p>实际上，相比于两台宿主机之间的直接通信，基于 Flannel UDP 模式的容器通信多了一个额外的步骤，即 flanneld 的处理过程。而这个过程，由于使用到了 flannel0 这个 TUN 设备，仅在发出 IP 包的过程中，就需要经过三次用户态与内核态之间的数据拷贝，如下所示：<br><img src="flannel-02.png" alt=""></p><p>第一次：用户态的容器进程发出的 IP 包经过 docker0 网桥进入内核态；</p><p>第二次：IP 包根据路由表进入 TUN（flannel0）设备，从而回到用户态的 flanneld 进程；</p><p>第三次：flanneld 进行 UDP 封包之后重新进入内核态，将 UDP 包通过宿主机的 eth0 发出去。</p><p>此外，Flannel 进行 UDP 封装（Encapsulation）和解封装（Decapsulation）的过程，也都是在用户态完成的。在 Linux 操作系统中，上述这些上下文切换和用户态操作的代价其实是比较高的，这也正是造成 Flannel UDP 模式性能不好的主要原因。</p><p>所以说，在进行系统级编程的时候，有一个非常重要的优化原则，就是要减少用户态到内核态的切换次数，并且把核心的处理逻辑都放在内核态进行。这也是为什么，Flannel 后来支持的VXLAN 模式，逐渐成为了主流的容器网络方案的原因。</p><h1 id="VXLAN"><a href="#VXLAN" class="headerlink" title="VXLAN"></a>VXLAN</h1><p>VXLAN，即 Virtual Extensible LAN（虚拟可扩展局域网），是 Linux 内核本身就支持的一种网络虚似化技术。所以说，VXLAN 可以完全在内核态实现上述封装和解封装的工作，从而通过与前面相似的“隧道”机制，构建出覆盖网络（Overlay Network）。</p><p>VXLAN 的覆盖网络的设计思想是：在现有的三层网络之上，“覆盖”一层虚拟的、由内核 VXLAN 模块负责维护的二层网络，使得连接在这个 VXLAN 二层网络上的“主机”（虚拟机或者容器都可以）之间，可以像在同一个局域网（LAN）里那样自由通信。当然，实际上，这些“主机”可能分布在不同的宿主机上，甚至是分布在不同的物理机房里。</p><p>而为了能够在二层网络上打通“隧道”，VXLAN 会在宿主机上设置一个特殊的网络设备作为“隧道”的两端。这个设备就叫作 VTEP，即：VXLAN Tunnel End Point（虚拟隧道端点）。</p><p>而 VTEP 设备的作用，其实跟前面的 flanneld 进程非常相似。只不过，它进行封装和解封装的对象，是二层数据帧（Ethernet frame）；而且这个工作的执行流程，全部是在内核里完成的（因为 VXLAN 本身就是 Linux 内核中的一个模块）。</p><p>上述基于 VTEP 设备进行“隧道”通信的流程，如下所示：<br><img src="flannel-03.png" alt=""></p><h1 id="host-gw"><a href="#host-gw" class="headerlink" title="host-gw"></a>host-gw</h1><p><img src="flannel-04.png" alt=""><br>host-gw 的性能损失大约在 10% 左右，而其他所有基于 VXLAN“隧道”机制的网络方案，性能损失都在 20%~30% 左右。</p><p>host-gw 模式能够正常工作的核心，就在于 IP 包在封装成帧发送出去的时候，会使用路由表里的“下一跳”来设置目的 MAC 地址。这样，它就会经过二层网络到达目的宿主机。</p><p>所以说，Flannel host-gw 模式必须要求集群宿主机之间是二层连通的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Flannel&quot;&gt;&lt;a href=&quot;#Flannel&quot; class=&quot;headerlink&quot; title=&quot;Flannel&quot;&gt;&lt;/a&gt;Flannel&lt;/h1&gt;&lt;p&gt;Flannel 项目是 CoreOS 公司主推的容器网络方案。事实上，Flannel 项目本身只是一
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>ETCD Operator</title>
    <link href="https://bamboox.online/2019/02/02/k8s-11-operator-02/"/>
    <id>https://bamboox.online/2019/02/02/k8s-11-operator-02/</id>
    <published>2019-02-02T22:49:50.000Z</published>
    <updated>2019-11-19T15:40:25.010Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ETCD-Operator"><a href="#ETCD-Operator" class="headerlink" title="ETCD Operator"></a>ETCD Operator</h1><p> 在 Kuernetes 生态中，Operator可以更加灵活和编程友好的管理“有状态应用”的 比如 数据库</p><h1 id="快速试用"><a href="#快速试用" class="headerlink" title="快速试用"></a>快速试用</h1><p><a href="https://github.com/coreos/etcd-operator" target="_blank" rel="noopener">https://github.com/coreos/etcd-operator</a></p><pre><code>$ git clone https://github.com/coreos/etcd-operator$ example/rbac/create_role.sh</code></pre><p>这个脚本的作用，就是为 Etcd Operator 创建 RBAC 规则。这是因为，Etcd Operator 需要访问 Kubernetes 的 APIServer 来创建对象</p><ol><li>对 Pod、Service、PVC、Deployment、Secret 等 API 对象，有所有权限；</li><li>对 CRD 对象，有所有权限；</li><li>对属于 etcd.database.coreos.com 这个 API Group 的 CR（Custom Resource）对象，有所有权限。</li></ol><p>而 Etcd Operator 本身，其实就是一个 Deployment，它的 YAML 文件如下所示：</p><pre><code>apiVersion: extensions/v1beta1kind: Deploymentmetadata:  name: etcd-operatorspec:  replicas: 1  template:    metadata:      labels:        name: etcd-operator    spec:      containers:      - name: etcd-operator        image: quay.io/coreos/etcd-operator:v0.9.4        command:        - etcd-operator        # Uncomment to act for resources in all namespaces. More information in doc/user/clusterwide.md        #- -cluster-wide        env:        - name: MY_POD_NAMESPACE          valueFrom:            fieldRef:              fieldPath: metadata.namespace        - name: MY_POD_NAME          valueFrom:            fieldRef:              fieldPath: metadata.name</code></pre><pre><code>$ kubectl get podsNAME                              READY     STATUS      RESTARTS   AGEetcd-operator-649dbdb5cb-bzfzp    1/1       Running     0          20s$ kubectl get crdNAME                                    CREATED ATetcdclusters.etcd.database.coreos.com   2019-03-01T18:42:55Z</code></pre><p>这个 CRD 名叫etcdclusters.etcd.database.coreos.com 。你可以通过 kubectl describe 命令看到它的细节，如下所示：</p><pre><code>$ kubectl describe crd  etcdclusters.etcd.database.coreos.com...Group:   etcd.database.coreos.com  Names:    Kind:       EtcdCluster    List Kind:  EtcdClusterList    Plural:     etcdclusters    Short Names:      etcd    Singular:  etcdcluster  Scope:       Namespaced  Version:     v1beta2...</code></pre><p>通过上述步骤创建 etcd.database.coreos.com API 组（Group）<br>如果有API 资源类型（Kind）是“EtcdCluster”的 YAML 文件被提交上来 K8s将会识别</p><p>提交 EtcdCluster</p><pre><code>$ kubectl apply -f example/example-etcd-cluster.yaml$ kubectl get podsNAME                            READY     STATUS    RESTARTS   AGEexample-etcd-cluster-dp8nqtjznc   1/1       Running     0          1mexample-etcd-cluster-mbzlg6sd56   1/1       Running     0          2mexample-etcd-cluster-v6v6s6stxd   1/1       Running     0          2m</code></pre><h2 id="example-etcd-如果被创建出来"><a href="#example-etcd-如果被创建出来" class="headerlink" title="example-etcd 如果被创建出来"></a>example-etcd 如果被创建出来</h2><p>Operator 的工作原理，实际上是利用了 Kubernetes 的自定义 API 资源（CRD），来描述想要部署的“有状态应用”；然后在自定义控制器里，根据自定义 API 对象的变化，来完成具体的部署和运维工作。</p><p>Etcd Operator 部署 Etcd 集群，采用的是静态集群（Static）的方式。</p><p>静态集群的好处是，它不必依赖于一个额外的服务发现机制来组建集群，非常适合本地容器化部署。而它的难点，则在于你必须在部署的时候，就规划好这个集群的拓扑结构，并且能够知道这些节点固定的 IP 地址。比如下面这个例子：</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls http://10.0.1.10:2380 \  --listen-peer-urls http://10.0.1.10:2380 \...  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \  --initial-cluster-state new$ etcd --name infra1 --initial-advertise-peer-urls http://10.0.1.11:2380 \  --listen-peer-urls http://10.0.1.11:2380 \...  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \  --initial-cluster-state new$ etcd --name infra2 --initial-advertise-peer-urls http://10.0.1.12:2380 \  --listen-peer-urls http://10.0.1.12:2380 \...  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \  --initial-cluster-state new</code></pre><p>在这个例子中，启动了三个 Etcd 进程，组成了一个三节点的 Etcd 集群。</p><p>其中，这些节点启动参数里的–initial-cluster 参数，非常值得你关注。它的含义，正是当前节点启动时集群的拓扑结构。说得更详细一点，就是当前这个节点启动时，需要跟哪些节点通信来组成集群。</p><h1 id="Etcd-集群创建分析"><a href="#Etcd-集群创建分析" class="headerlink" title="Etcd 集群创建分析"></a>Etcd 集群创建分析</h1><p>EtcdCluster 这个 CRD 的定义，它对应的 types.go 文件的主要内容，如下所示：</p><pre><code>// +genclient// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Objecttype EtcdCluster struct {  metav1.TypeMeta   `json:&quot;,inline&quot;`  metav1.ObjectMeta `json:&quot;metadata,omitempty&quot;`  Spec              ClusterSpec   `json:&quot;spec&quot;`  Status            ClusterStatus `json:&quot;status&quot;`}type ClusterSpec struct { // Size is the expected size of the etcd cluster. // The etcd-operator will eventually make the size of the running // cluster equal to the expected size. // The vaild range of the size is from 1 to 7. Size int `json:&quot;size&quot;` ... }</code></pre><p>可以看到，EtcdCluster 是一个有 Status 字段的 CRD。在这里，可以不必关心 ClusterSpec 里的其他字段，只关注 Size（即：Etcd 集群的大小）字段即可。</p><p>Size 字段的存在，就意味着将来如果想要调整集群大小的话，应该直接修改 YAML 文件里 size 的值，并执行 kubectl apply -f。</p><p>这样，Operator 就会完成 Etcd 节点的增删操作。这种“scale”能力，也是 Etcd Operator 自动化运维 Etcd 集群需要实现的主要功能。</p><p>而为了能够支持这个功能，不再像前面那样在–initial-cluster 参数里把拓扑结构固定死。</p><p>所以，Etcd Operator 的实现，虽然选择的也是静态集群，但这个集群具体的组建过程，是逐个节点动态添加的方式，即：<br>首先，Etcd Operator 会创建一个“种子节点”；<br>然后，Etcd Operator 会不断创建新的 Etcd 节点，然后将它们逐一加入到这个集群当中，直到集群的节点数等于 size。</p><p>ETCDOperator创建集群可以分为俩个步骤</p><ol><li><p>Bootstrap<br>infra0 节点为例，它的 IP 地址是 10.0.1.10，那么 Etcd Operator 生成的种子节点的启动命令，如下所示：</p><pre><code>$ etcd--data-dir=/var/etcd/data--name=infra0--initial-advertise-peer-urls=http://10.0.1.10:2380--listen-peer-urls=http://0.0.0.0:2380--listen-client-urls=http://0.0.0.0:2379--advertise-client-urls=http://10.0.1.10:2379--initial-cluster=infra0=http://10.0.1.10:2380--initial-cluster-state=new--initial-cluster-token=4b5215fa-5401-4a95-a8c6-892317c9bef8  </code></pre><p>，这个种子节点的 initial-cluster-state 是 new，并且指定了唯一的 initial-cluster-token 参数。</p><ol start="2"><li>AddNode</li></ol></li></ol><pre><code> etcdctl member add infra1 http://10.0.1.11:2380$ etcd    --data-dir=/var/etcd/data    --name=infra1    --initial-advertise-peer-urls=http://10.0.1.11:2380    --listen-peer-urls=http://0.0.0.0:2380    --listen-client-urls=http://0.0.0.0:2379    --advertise-client-urls=http://10.0.1.11:2379    --initial-cluster=infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380    --initial-cluster-state=existing</code></pre><p>对于这个 infra1 成员节点来说，它的 initial-cluster-state 是 existing，也就是要加入已有集群。而它的 initial-cluster 的值，则变成了 infra0 和 infra1 两个节点的 IP 地址。</p><p>所以，以此类推，不断地将 infra2 等后续成员添加到集群中，直到整个集群的节点数目等于用户指定的 size 之后，部署就完成了。</p><h1 id="ETCDOperator源码分析"><a href="#ETCDOperator源码分析" class="headerlink" title="ETCDOperator源码分析"></a>ETCDOperator源码分析</h1><p>Etcd Operator 的启动流程也是围绕着 Informer 展开的，如下所示：</p><pre><code>func (c *Controller) Start() error { for {  err := c.initResource()  ...  time.Sleep(initRetryWaitTime) } c.run()}func (c *Controller) run() { ... _, informer := cache.NewIndexerInformer(source, &amp;api.EtcdCluster{}, 0, cache.ResourceEventHandlerFuncs{  AddFunc:    c.onAddEtcdClus,  UpdateFunc: c.onUpdateEtcdClus,  DeleteFunc: c.onDeleteEtcdClus, }, cache.Indexers{}) ctx := context.TODO() // TODO: use workqueue to avoid blocking informer.Run(ctx.Done())}</code></pre><p>可以看到，Etcd Operator 启动要做的第一件事（ c.initResource），是创建 EtcdCluster 对象所需要的 CRD，即：前面提到的etcdclusters.etcd.database.coreos.com。这样 Kubernetes 就能够“认识”EtcdCluster 这个自定义 API 资源了。</p><p>而接下来，Etcd Operator 会定义一个 EtcdCluster 对象的 Informer。</p><p>不过，需要注意的是，由于 Etcd Operator 的完成时间相对较早，所以它里面有些代码的编写方式会跟之前讲解的最新的编写方式不太一样。在具体实践的时候，你还是应该以我讲解的模板为主。</p><p>比如，在上面的代码最后，你会看到有这样一句注释：</p><pre><code>// TODO: use workqueue to avoid blocking</code></pre><p>Etcd Operator 并没有用工作队列来协调 Informer 和控制循环<br>不过KuberBuilder 创建的Operator实现了该功能</p><p>在控制循环里执行的业务逻辑，往往是比较耗时间的。比如，创建一个真实的 Etcd 集群。而 Informer 的 WATCH 机制对 API 对象变化的响应，则非常迅速。所以，控制器里的业务逻辑就很可能会拖慢 Informer 的执行周期，甚至可能 Block 它。而要协调这样两个快、慢任务的一个典型解决方法，就是引入一个工作队列</p><p>由于 Etcd Operator 里没有工作队列，那么在它的 EventHandler 部分，就不会有什么入队操作，而直接就是每种事件对应的具体的业务逻辑了。</p><p><img src="etcd-operator.jpg" alt=""></p><h1 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h1><p>CRD 并不是万能的，它有很多场景不适用，还有性能瓶颈。你能列举出一些不适用 CRD 的场景么？你知道造成 CRD 性能瓶颈的原因主要在哪里么？</p><p>CRD 目前不支持 protobuf，当 API Object 数量 &gt;1K，或者单个对象 &gt;1KB，或者高频请求时，CRD 的响应都会有问题。 所以，CRD 千万不能也不应该被当作数据库使用。</p><p>其实像 Kubernetes ，或者说 Etcd 本身，最佳的使用场景就是作为配置管理的依赖。此外，如果业务需求不能用 CRD 进行建模的时候，比如，需要等待 API 最终返回，或者需要检查 API 的返回值，也是不能用 CRD 的。同时，当你需要完整的 APIServer 而不是只关心 API 对象的时候，使用 API Aggregator</p><h2 id="API-Aggregator"><a href="#API-Aggregator" class="headerlink" title="API Aggregator"></a>API Aggregator</h2><p><img src="aggregator.png" alt=""></p><h1 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h1><p><a href="https://github.com/kubernetes-incubator/metrics-server" target="_blank" rel="noopener">https://github.com/kubernetes-incubator/metrics-server</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ETCD-Operator&quot;&gt;&lt;a href=&quot;#ETCD-Operator&quot; class=&quot;headerlink&quot; title=&quot;ETCD Operator&quot;&gt;&lt;/a&gt;ETCD Operator&lt;/h1&gt;&lt;p&gt; 在 Kuernetes 生态中，Operator可
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>K8s Operator</title>
    <link href="https://bamboox.online/2019/02/01/k8s-11-operator-01/"/>
    <id>https://bamboox.online/2019/02/01/k8s-11-operator-01/</id>
    <published>2019-02-01T22:49:50.000Z</published>
    <updated>2019-11-19T15:40:25.010Z</updated>
    
    <content type="html"><![CDATA[<h1 id="What-is-Operator？"><a href="#What-is-Operator？" class="headerlink" title="What is Operator？"></a>What is Operator？</h1><p>Operator是管理特定应用程序的控制器，通过扩展kubernetes api以软件的方式帮助kubernetes用户创建，配置和管理复杂有状态的应用程序实例(etcd,redis,mysql,prometheus等等)。它建立在基本的Kubernetes资源和控制器概念的基础上，它包含管理特定应用程序的操作以及实现常见任务的自动化。</p><h1 id="Stateless-is-Easy-Stateful-is-Hard"><a href="#Stateless-is-Easy-Stateful-is-Hard" class="headerlink" title="Stateless is Easy, Stateful is Hard"></a>Stateless is Easy, Stateful is Hard</h1><p>有了kubernetes，管理和扩展web应用，移动后端和api服务就变得相对容易了。<br>why？因为这些应用程序通常是无状态的，可以通过基本的Kubernetes APIs就能run起来，例如通过Deployments资源，可以在没有额外的知识的情况下扩展我们的应用程序并可以从故障中恢复。<br>一个更大的挑战是管理有状态的应用程序，如数据库，缓存和监控系统。<br>这些系统需要学习相关的知识来正确扩展，升级和重新加载配置，同时防止数据丢失或不可用。我们希望将这种特定于应用程序的操作知识通过编码解决，利用强大的kubernetes抽象的软件实现，以正确运行和管理应用程序。</p><h1 id="Lifecycle-of-an-Operator"><a href="#Lifecycle-of-an-Operator" class="headerlink" title="Lifecycle of an Operator"></a>Lifecycle of an Operator</h1><p><img src="run-only.png" alt=""><br>构建后，需要在Kubernetes集群上部署operator。Operator Lifecycle Manager是便于管理Kubernetes集群上operator的背板。有了它，管理员可以控制operator在哪些命名空间中可用，以及谁可以与正在运行的操作员交互。他们还可以管理运营商及其资源的整个生命周期，例如触发对运营商及其资源的更新。</p><h1 id="Why-Kubernetes-Operators-are-a-game-changer"><a href="#Why-Kubernetes-Operators-are-a-game-changer" class="headerlink" title="Why Kubernetes Operators are a game changer"></a>Why Kubernetes Operators are a game changer</h1><p>控制器能够直接访问Kubernetes API，这意味着它们可以监控集群，改变Pod/服务，扩容/缩容，以及调用运行着的应用程序的endpoint，所有这些都根据编写在这些控制器里的自定义规则来实现。</p><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ul><li><a href="https://coreos.com/operators/" target="_blank" rel="noopener">https://coreos.com/operators/</a></li><li><a href="https://blog.couchbase.com/kubernetes-operators-game-changer/" target="_blank" rel="noopener">https://blog.couchbase.com/kubernetes-operators-game-changer/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;What-is-Operator？&quot;&gt;&lt;a href=&quot;#What-is-Operator？&quot; class=&quot;headerlink&quot; title=&quot;What is Operator？&quot;&gt;&lt;/a&gt;What is Operator？&lt;/h1&gt;&lt;p&gt;Operator是管
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>K8s apiserver 权限</title>
    <link href="https://bamboox.online/2019/01/26/k8s-9-apiserver-quan-xian/"/>
    <id>https://bamboox.online/2019/01/26/k8s-9-apiserver-quan-xian/</id>
    <published>2019-01-26T22:49:50.000Z</published>
    <updated>2019-11-19T15:40:25.014Z</updated>
    
    <content type="html"><![CDATA[<h1 id="认证类型"><a href="#认证类型" class="headerlink" title="认证类型"></a>认证类型</h1><p>kubernetes 提供了三种级别的客户端认证方式：</p><ul><li>HTTPS证书认证，是基于CA根证书签名的双向数字证书认证方 式，是最严格的认证</li><li>HTTP Token认证，通过Token识别每个合法的用户</li><li>HTTP Basic认证</li></ul><p>HTTP Token认证和Http Basic认证是相对简单的认证方式，Kubernetes的各组件与Api Server的通信方式仍然是HTTPS，但不再使用CA数字证书。</p><p>基于CA证书的双向认证</p><p>我们注意到有如下三个启动参数：</p><ul><li>–client-ca-file: 指定CA根证书文件为/etc/kubernetes/pki/ca.pem，内置CA公钥用于验证某证书是否是CA签发的证书</li><li>–tls-private-key-file: 指定ApiServer私钥文件为/etc/kubernetes/pki/apiserver-key.pem</li><li>–tls-cert-file：指定ApiServer证书文件为/etc/kubernetes/pki/apiserver.pem</li></ul><p>说明Api Server已经启动了HTTPS证书认证，此时如果在集群外部使用浏览器访问https://:6443/api会提示Unauthorized。</p><a id="more"></a><p>生成客户端私钥和证书<br>客户端要通过https证书双向认证的形式访问apiserver需要生成客户端的私钥和证书。在最新版本的kubernetes中，已经不再需要手动为客户端生成证书。直接由Master端签发即可。</p><p>master端允许其证书申请：</p><pre><code># 查看 csr➜  kubectl get csrNAME        AGE       REQUESTOR           CONDITIONcsr-l9d25   2m        kubelet-bootstrap   Pending# 签发证书➜  kubectl certificate approve csr-l9d25certificatesigningrequest &quot;csr-l9d25&quot; approved</code></pre><p>master核心组件与apiserver的认证方式<br>/etc/kubernetes/manifests下的kube-controller-manager.json和kube-scheduler.json说明Controller Manager和Scheduler都是以静态Pod的形式运行在Master Node上，注意到这两个文件里的启动参数–master=127.0.0.1:8080，说明它们直接通过insecure-port 8080和ApiServer通信。 而前面ApiServer的–insecure-bind-address=127.0.0.1，因此他们之间无需走secure-port。</p><h2 id="HTTP-Token认证"><a href="#HTTP-Token认证" class="headerlink" title="HTTP Token认证"></a>HTTP Token认证</h2><p>在上面master node的apiserver的启动命令里面，除了证书的双向认证，还同时启动了token认证。</p><p>–token-auth-file=/etc/kubernetes/pki/token.csv 指定了静态token文件，这个文件的格式如下：</p><pre><code>token,user,uid,&quot;group1,group2,group3&quot;</code></pre><p>生成token方式如下：</p><pre><code>export BOOTSTRAP_TOKEN=$(head -c 16 /dev/urandom | od -An -t x | tr -d &#39; &#39;)cat &gt; token.csv &lt;&lt;EOF${BOOTSTRAP_TOKEN},kubelet-bootstrap,10001,&quot;system:kubelet-bootstrap&quot;EOF</code></pre><p>请求Api时只要在Authorization头中加入Bearer Token即可：</p><pre><code>curl -k --header &quot;Authorization: Bearer fe0b40f90ac632c26d79c39673f3dd80&quot; https://10.1.61.129:6443/api{  &quot;kind&quot;: &quot;APIVersions&quot;,  &quot;versions&quot;: [    &quot;v1&quot;  ],  &quot;serverAddressByClientCIDRs&quot;: [    {      &quot;clientCIDR&quot;: &quot;0.0.0.0/0&quot;,      &quot;serverAddress&quot;: &quot;10.1.61.129:6443&quot;    }  ]}</code></pre><p>kubectl使用Bearer访问apiserver：</p><pre><code>kubectl --server=https://10.1.61.129:6443 \--token=fe0b40f90ac632c26d79c39673f3dd80 \--insecure-skip-tls-verify=true \cluster-info</code></pre><h2 id="HTTP-Basic认证"><a href="#HTTP-Basic认证" class="headerlink" title="HTTP Basic认证"></a>HTTP Basic认证</h2><p>kubeadm在初始化集群时并没有开启http basic认证，官方也不建议在实践中使用。但是，在前面的两种认证方式中，如果我们要在外部通过https的方式访问dashboard，则无法办到，除非对外开启apiserver非安全认证的8080端口，这显然不是我们想看到的。在这种情况 下，我们就可以开启http basic认证，既可以通过https的方式 在外部打开dashboard，同时还能提供基本的安全认证。在这里也简单的列一下http basic认证的配置。</p><ol><li><p>在master上创建/etc/kubernetes/basic_auth文件，文件中每行的格式如下：<br>password,user,uid,”group1,group2,group3”<br>示例如下：<br>1234,admin,1</p></li><li><p>在启动apiserver的时候，启动项添加如下参数即可：</p></li></ol><p>–basic_auth_file=/etc/kubernetes/basic_auth</p><p>使用请求头Authorization Basic BASE64ENCODED(USER:PASSWORD)访问方式如下：</p><pre><code>echo admin:1234|base64YWRtaW46MTIzNAo=curl -k --header &quot;Authorization:Basic YWRtaW46MTIzNAo=&quot; https://10.1.61.129:6443/api{  &quot;kind&quot;: &quot;APIVersions&quot;,  &quot;versions&quot;: [    &quot;v1&quot;  ],  &quot;serverAddressByClientCIDRs&quot;: [    {      &quot;clientCIDR&quot;: &quot;0.0.0.0/0&quot;,      &quot;serverAddress&quot;: &quot;10.1.61.129:6443&quot;    }  ]}</code></pre><p>使用kubectl访问如下：<br>kubectl –server=<a href="https://10.1.61.129:6443" target="_blank" rel="noopener">https://10.1.61.129:6443</a> <br>–username=admin <br>–password=1234 <br>–insecure-skip-tls-verify=true <br>cluster-info</p><h1 id="kubectl-config简要说明"><a href="#kubectl-config简要说明" class="headerlink" title="kubectl config简要说明"></a>kubectl config简要说明</h1><pre><code># kubectl config viewapiVersion: v1clusters:- cluster:    certificate-authority-data: REDACTED    server: https://172.16.66.101:6443  name: kubernetescontexts:- context:    cluster: kubernetes    user: kubernetes-admin  name: kubernetes-admin@kubernetescurrent-context: kubernetes-admin@kuberneteskind: Configpreferences: {}users:- name: kubernetes-admin  user:    client-certificate-data: REDACTED    client-key-data: REDACTED</code></pre><p>首先我们将 /etc/kubernetes/admin.conf中client-certificate-data的数据内容保存到一个临时文件admin-client-certificate.txt中：</p><p>然后针对该文件数据做base64解码，得到client certificate文件：</p><pre><code>cat admin-client-certificate.txt | base64 -d &gt; admin-client.crt# cat admin-client.crt-----BEGIN CERTIFICATE-----MIIC8jCCAdqgAwIBAgIIf2dVRjm8ELQwDQYJKoZIhvcNAQELBQAwFTETMBEGA1UEAxMKa3ViZXJuZXRlczAeFw0xODA1MTQwODE3MTNaFw0xOTA1MTQwODE3MTdaMDQxFzAVBgNVBAoTDnN5c3RlbTptYXN0ZXJzMRkwFwYDVQQDExBrdWJlcm5ldGVzLWFkbWluMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxBn3jdw80b1Gfb6sw2NrqpLotMT4nyAf2HhqMrXjnO+wnaK1AITOw/22mDj0rwIuJwdQIj5/BaF63pPEpU0vhIPVK4n6JI4dmMzo/lR3jZpGeZW1zdXaCovw9c7clbiHo/mFG4xqytVLfX4/S8mFp2A9QcieJGIo5S0BR3FZlU1PM7DRbLDVVq1PdyNY2GfsbGrHlGgXvWAKCd/H79gAqVoTXjSIWCVYuYcoLvdvVXQSIiYlpXFP1jBQLvcU7vrqtb12RmrxnpkW4pldGEOX2sLmfYZ5TiFpkRwz2GxsmWyRbt6OuISJFI6RZ0r+Rn4yMDKPrYlEngDVc5KPZ5zmwIDAQABoycwJTAOBgNVHQ8BAf8EBAMCBaAwEwYDVR0lBAwwCgYIKwYBBQUHAwIwDQYJKoZIhvcNAQELBQADggEBAEZNTvTz2OgzCUdvMFbrhPsp+mD2vPjMRCxiBkA10vICOSfdymMn8aw0IbKYz2gQbXqUfqzQmQfa3if+QYBkB+77zfsv9am4EP/e6Tg52tqV2P7s2eF7tNAe20GyV6yFlQ1QUW5/M4M+JMlV+BUbl9yEyQlENucKf+uTPyKKTUtzvUYr5E3EJkt84EQINvw2nR2jNveZ1XWOliUrKfjHHtfvO/n56USuI4wu2LTlICRcj4g+ZWlIjeMFkGyPbJyJAQ65P2sGrZm1klGGH3mzwO5CP1yZWvoUjjPjzSjMCIaK/fR8eRAJ6q1tT6bG26L+njkKCQDWKpjAWOapuROcbk=-----END CERTIFICATE-----</code></pre><p>查看证书内容：</p><pre><code># openssl x509 -in ./admin-client.crt -textCertificate:    Data:        Version: 3 (0x2)        Serial Number: 9180400125522743476 (0x7f67554639bc10b4)    Signature Algorithm: sha256WithRSAEncryption        Issuer: CN=kubernetes        Validity            Not Before: May 14 08:17:13 2018 GMT            Not After : May 14 08:17:17 2019 GMT        Subject: O=system:masters, CN=kubernetes-admin        Subject Public Key Info:            Public Key Algorithm: rsaEncryption                Public-Key: (2048 bit)   ... ...</code></pre><p>从证书输出的信息中，我们看到了下面这行：</p><pre><code>Subject: O=system:masters, CN=kubernetes-admin</code></pre><p>k8s apiserver对kubectl的请求进行client certificate验证(通过ca证书–client-ca-file=/etc/kubernetes/pki/ca.crt对其进行校验)，验证通过后kube-apiserver会得到： group = system:masters 的http上下文信息，并传给后续的authorizers。</p><h3 id="在授权-authorization-时根据Group确定所绑定的角色-Role"><a href="#在授权-authorization-时根据Group确定所绑定的角色-Role" class="headerlink" title="在授权(authorization)时根据Group确定所绑定的角色(Role)"></a>在授权(authorization)时根据Group确定所绑定的角色(Role)</h3><p>kubeadm在init初始引导集群启动过程中，创建了许多default的role、clusterrole、rolebinding和clusterrolebinding，  </p><p><a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/access-authn-authz/rbac/</a></p><table><thead><tr><th align="left">Default ClusterRole</th><th align="center">Default ClusterRoleBinding</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left">cluster-admin</td><td align="center">system:masters group</td><td align="left">Allows super-user access to perform any action on any resource. When used in a ClusterRoleBinding, it gives full control over every resource in the cluster and in all namespaces. When used in a RoleBinding, it gives full control over every resource in the rolebinding’s namespace, including the namespace itself.</td></tr><tr><td align="left">admin</td><td align="center">None</td><td align="left">Allows admin access, intended to be granted within a namespace using a RoleBinding. If used in a RoleBinding, allows read/write access to most resources in a namespace, including the ability to create roles and rolebindings within the namespace. It does not allow write access to resource quota or to the namespace itself.</td></tr><tr><td align="left">edit</td><td align="center">None</td><td align="left">Allows read/write access to most objects in a namespace. It does not allow viewing or modifying roles or rolebindings.</td></tr><tr><td align="left">view</td><td align="center">None</td><td align="left">Allows read-only access to see most objects in a namespace. It does not allow viewing roles or rolebindings. It does not allow viewing secrets, since those are escalating.</td></tr><tr><td align="left"></td><td align="center"></td><td align="left"></td></tr></tbody></table><p>其中第一个 cluster-admin 这个cluster role binding绑定了 system:masters group，这和authentication环节传递过来的身份信息不谋而合。沿着 system:masters group对应的cluster-admin clusterrolebinding“追查”下去，真相就会浮出水面。</p><p>我们查看一下这一binding：</p><pre><code># kubectl get clusterrolebinding/cluster-admin -n kube-system -o yamlapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata:  annotations:    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;  creationTimestamp: 2018-06-07T06:14:55Z  labels:    kubernetes.io/bootstrapping: rbac-defaults  name: cluster-admin  resourceVersion: &quot;103&quot;  selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/cluster-admin  uid: 18c89690-6a1a-11e8-a0e8-00163e0cd764roleRef:  apiGroup: rbac.authorization.k8s.io  kind: ClusterRole  name: cluster-adminsubjects:- apiGroup: rbac.authorization.k8s.io  kind: Group  name: system:masters</code></pre><p>我们看到在kube-system名字空间中，一个名为cluster-admin的clusterrolebinding将cluster-admin cluster role与system:masters Group绑定到了一起，赋予了所有归属于system:masters Group中用户cluster-admin角色所拥有的权限。</p><p>我们再来查看一下cluster-admin这个role的具体权限信息：</p><pre><code># kubectl get clusterrole/cluster-admin -n kube-system -o yamlapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata:  annotations:    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;  creationTimestamp: 2018-06-07T06:14:55Z  labels:    kubernetes.io/bootstrapping: rbac-defaults  name: cluster-admin  resourceVersion: &quot;52&quot;  selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/cluster-admin  uid: 18abe535-6a1a-11e8-a0e8-00163e0cd764rules:- apiGroups:  - &#39;*&#39;  resources:  - &#39;*&#39;  verbs:  - &#39;*&#39;- nonResourceURLs:  - &#39;*&#39;  verbs:  - &#39;*&#39;</code></pre><p>从rules列表中来看，cluster-admin这个角色对所有resources、verbs、apiGroups均有无限制的操作权限，即整个集群的root权限。于是kubectl的请求就可以操控和管理整个集群了。</p><p>至此，我们应该明确了为什么采用了admin.conf kubeconfig的kubectrl拥有root权限了。下面是一幅示意图，简要总结了对kubectl访问请求的身份验证和授权过程：</p><p><img src="how-kubectl-be-authorized.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;认证类型&quot;&gt;&lt;a href=&quot;#认证类型&quot; class=&quot;headerlink&quot; title=&quot;认证类型&quot;&gt;&lt;/a&gt;认证类型&lt;/h1&gt;&lt;p&gt;kubernetes 提供了三种级别的客户端认证方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HTTPS证书认证，是基于CA根证书签名的双向数字证书认证方 式，是最严格的认证&lt;/li&gt;
&lt;li&gt;HTTP Token认证，通过Token识别每个合法的用户&lt;/li&gt;
&lt;li&gt;HTTP Basic认证&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HTTP Token认证和Http Basic认证是相对简单的认证方式，Kubernetes的各组件与Api Server的通信方式仍然是HTTPS，但不再使用CA数字证书。&lt;/p&gt;
&lt;p&gt;基于CA证书的双向认证&lt;/p&gt;
&lt;p&gt;我们注意到有如下三个启动参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;–client-ca-file: 指定CA根证书文件为/etc/kubernetes/pki/ca.pem，内置CA公钥用于验证某证书是否是CA签发的证书&lt;/li&gt;
&lt;li&gt;–tls-private-key-file: 指定ApiServer私钥文件为/etc/kubernetes/pki/apiserver-key.pem&lt;/li&gt;
&lt;li&gt;–tls-cert-file：指定ApiServer证书文件为/etc/kubernetes/pki/apiserver.pem&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;说明Api Server已经启动了HTTPS证书认证，此时如果在集群外部使用浏览器访问https://:6443/api会提示Unauthorized。&lt;/p&gt;
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>K8s job</title>
    <link href="https://bamboox.online/2019/01/25/k8s-8/"/>
    <id>https://bamboox.online/2019/01/25/k8s-8/</id>
    <published>2019-01-25T22:49:50.000Z</published>
    <updated>2019-11-19T15:40:25.014Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h1><p>Job负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个Pod成功结束。</p><h2 id="Job-Spec格式"><a href="#Job-Spec格式" class="headerlink" title="Job Spec格式"></a>Job Spec格式</h2><ul><li>spec.template格式同Pod</li><li>RestartPolicy仅支持Never或OnFailure</li><li>单个Pod时，默认Pod成功运行后Job即结束</li><li>.spec.completions标志Job结束需要成功运行的Pod个数，默认为1</li><li>.spec.parallelism标志并行运行的Pod的个数，默认为1</li><li>spec.activeDeadlineSeconds标志失败Pod的重试最大时间，超过这个时间不会继续重试</li></ul><h1 id="CronJob"><a href="#CronJob" class="headerlink" title="CronJob"></a>CronJob</h1><p>Cron Job 管理基于时间的 Job，即：</p><ul><li>在给定时间点只运行一次</li><li>周期性地在给定时间点运行</li></ul><p>一个 CronJob 对象类似于 crontab （cron table）文件中的一行。它根据指定的预定计划周期性地运行一个 Job，格式可以参考 Cron </p><pre><code>apiVersion: batch/v1beta1kind: CronJobmetadata:  name: hellospec:  schedule: &quot;*/1 * * * *&quot;  jobTemplate:    spec:      template:        spec:          containers:          - name: hello            image: alpine            args:            - /bin/sh            - -c          # - date; echo Hello from the Kubernetes cluster; sleep 120;            - date; echo Hello from the Kubernetes cluster;          restartPolicy: OnFailure</code></pre><h1 id="CronJob-Spec"><a href="#CronJob-Spec" class="headerlink" title="CronJob Spec"></a>CronJob Spec</h1><ul><li><p>.spec.schedule：调度，必需字段，指定任务运行周期，格式同 Cron</p></li><li><p>.spec.jobTemplate：Job 模板，必需字段，指定需要运行的任务，格式同 Job</p></li><li><p>.spec.startingDeadlineSeconds ：启动 Job 的期限（秒级别），该字段是可选的。如果因为任何原因而错过了被调度的时间，那么错过执行时间的 Job 将被认为是失败的。如果没有指定，则没有期限</p></li><li><p>.spec.concurrencyPolicy：并发策略，该字段也是可选的。它指定了如何处理被 Cron Job 创建的 Job 的并发执行。只允许指定下面策略中的一种：</p><ul><li>Allow（默认）：允许并发运行 Job</li><li>Forbid：禁止并发运行，如果前一个还没有完成，则直接跳过下一个</li><li>Replace：取消当前正在运行的 Job，用一个新的来替换</li><li>注意，当前策略只能应用于同一个 Cron Job 创建的 Job。如果存在多个 Cron Job，它们创建的   Job 之间总是允许并发运行。</li></ul></li><li><p>.spec.suspend ：挂起，该字段也是可选的。如果设置为 true，后续所有执行都会被挂起。它对已经开始执行的 Job 不起作用。默认值为 false。</p></li><li><p>.spec.successfulJobsHistoryLimit 和 .spec.failedJobsHistoryLimit ：历史限制，是可选的字段。它们指定了可以保留多少完成和失败的 Job。<br>默认情况下，它们分别设置为 3 和 1。设置限制的值为 0，相关类型的 Job 完成后将不会被保留。</p></li></ul><p>命令：</p><ul><li>获取所有cronjob<br>kubectl get cronjob</li><li>查看hello cronjob<br>kubectl get cronjob hello</li><li>移除cronjob<br>kubectl delete cronjob hello<br>job running 强制kill 清空所有 hello job container</li></ul><h2 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h2><ul><li>每次都是创建一个新的容器</li><li>任务周期内未执行完,会重新启动一个容器</li><li>Unsupported value: “Always”: supported values: “OnFailure”, “Never”<br>注意Job的RestartPolicy仅支持Never和OnFailure两种，不支持Always，我们知道Job就相当于来执行一个批处理任务，执行完就结束了，如果支持Always的话是不是就陷入了死循环了？<ul><li>OnFailure: 失败重启容器</li><li>Never:失败 Failed</li></ul></li></ul><p><a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-%E7%9A%84%E7%94%9F%E5%91%BD" target="_blank" rel="noopener">pod生命周期</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Job&quot;&gt;&lt;a href=&quot;#Job&quot; class=&quot;headerlink&quot; title=&quot;Job&quot;&gt;&lt;/a&gt;Job&lt;/h1&gt;&lt;p&gt;Job负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个Pod成功结束。&lt;/p&gt;
&lt;h2 id=&quot;Job-Spec格式
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>K8s Ingress</title>
    <link href="https://bamboox.online/2019/01/20/k8s-6-ingress/"/>
    <id>https://bamboox.online/2019/01/20/k8s-6-ingress/</id>
    <published>2019-01-20T22:49:50.000Z</published>
    <updated>2019-11-19T15:40:25.014Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是Ingress"><a href="#什么是Ingress" class="headerlink" title="什么是Ingress"></a>什么是Ingress</h1><pre class="line-numbers language-java"><code class="language-java">     internet        <span class="token operator">|</span>   <span class="token punctuation">[</span> Ingress <span class="token punctuation">]</span>   <span class="token operator">--</span><span class="token operator">|</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">|</span><span class="token operator">--</span>   <span class="token punctuation">[</span> Services <span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Ingress可以配置为提供服务外部可访问的URL，负载平衡流量，SSL，并提供基于名称的虚拟主机。一个入口控制器负责履行入口，通常与负载均衡器，虽然它也可以配置您的边缘路由器或额外的前端，以帮助处理业务。</p><pre class="line-numbers language-java"><code class="language-java">foo<span class="token punctuation">.</span>bar<span class="token punctuation">.</span>com <span class="token operator">--</span><span class="token operator">|</span>                 <span class="token operator">|</span><span class="token operator">-</span><span class="token operator">></span> foo<span class="token punctuation">.</span>bar<span class="token punctuation">.</span>com s1<span class="token operator">:</span><span class="token number">80</span>              <span class="token operator">|</span> <span class="token number">178.91</span><span class="token punctuation">.</span><span class="token number">123.132</span>  <span class="token operator">|</span>bar<span class="token punctuation">.</span>foo<span class="token punctuation">.</span>com <span class="token operator">--</span><span class="token operator">|</span>                 <span class="token operator">|</span><span class="token operator">-</span><span class="token operator">></span> bar<span class="token punctuation">.</span>foo<span class="token punctuation">.</span>com s2<span class="token operator">:</span><span class="token number">80</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><a id="more"></a><h1 id="Nginx-Ingress-Controller"><a href="#Nginx-Ingress-Controller" class="headerlink" title="Nginx Ingress Controller"></a>Nginx Ingress Controller</h1><p>官方文档参考：<a href="https://kubernetes.github.io/ingress-nginx/deploy/" target="_blank" rel="noopener">https://kubernetes.github.io/ingress-nginx/deploy/</a></p><p>首先部署命名空间，默认后端（处理 404等），配置等，与官方一致。</p><pre class="line-numbers language-部署"><code class="language-部署">curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/namespace.yaml| kubectl apply -f -curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/default-backend.yaml | kubectl apply -f -curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/configmap.yaml| kubectl apply -f -<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>接着需要为 RBAC 配置角色和权限：</p><pre><code>curl https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/rbac.yaml| kubectl apply -f -</code></pre><p>Nginx 部署在 master 机器上，使用 master 的入口 ip 提供服务<br>官方文档部署完后仍然需要使用 Service 做转发，在没有 ELB 的情况下仍需使用 NodePort 方式暴露在高端口上</p><pre><code>apiVersion: extensions/v1beta1kind: Ingressmetadata:  name: submodule-checker-ingressspec:  rules:  - host: YOUR.HOST.NAME    http:      paths:      - backend:          serviceName: submodule-checker-service          servicePort: 7777</code></pre><p>配置完成后将域名解析到 k8s 集群的主节点上，即可访问服务内的 pod。</p><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>自动生成nginx config文件； 通过nginx 反向代理到各个service<br>对外出口还是有master机器转发，需要NodePort或者LoadBalancer（NodePort + VIP）</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么是Ingress&quot;&gt;&lt;a href=&quot;#什么是Ingress&quot; class=&quot;headerlink&quot; title=&quot;什么是Ingress&quot;&gt;&lt;/a&gt;什么是Ingress&lt;/h1&gt;&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;     internet
        |
   [ Ingress ]
   --|-----|--
   [ Services ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ingress可以配置为提供服务外部可访问的URL，负载平衡流量，SSL，并提供基于名称的虚拟主机。一个入口控制器负责履行入口，通常与负载均衡器，虽然它也可以配置您的边缘路由器或额外的前端，以帮助处理业务。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;java&quot;&gt;foo.bar.com --|                 |-&amp;gt; foo.bar.com s1:80
              | 178.91.123.132  |
bar.foo.com --|                 |-&amp;gt; bar.foo.com s2:80&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>K8s CCM</title>
    <link href="https://bamboox.online/2019/01/20/k8s-7/"/>
    <id>https://bamboox.online/2019/01/20/k8s-7/</id>
    <published>2019-01-20T22:49:50.000Z</published>
    <updated>2019-11-19T15:40:25.014Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Kubernetes-Cloud-Controller-Manager"><a href="#Kubernetes-Cloud-Controller-Manager" class="headerlink" title="Kubernetes Cloud Controller Manager"></a>Kubernetes Cloud Controller Manager</h1><p>ccm经历了很大的版本改动，之前版本ccm 开发需要改动K8s源码，版本管理非常麻烦<br>现在的版本中ccm被独立出来只需要实现K8s中的接口，就可以完成功能 这样对升级K8s 就非常轻松了</p><h2 id="service-controller"><a href="#service-controller" class="headerlink" title="service controller"></a>service controller</h2><p>开发service controller 对外提供LoadBalancer</p><h3 id="k8s中service主要有三种："><a href="#k8s中service主要有三种：" class="headerlink" title="k8s中service主要有三种："></a>k8s中service主要有三种：</h3><h5 id="ClusterIP"><a href="#ClusterIP" class="headerlink" title="ClusterIP"></a>ClusterIP</h5><p>use a cluster-internal IP only - this is the default and is discussed above. Choosing this value means that you want this service to be reachable only from inside of the cluster.</p><h5 id="NodePort"><a href="#NodePort" class="headerlink" title="NodePort"></a>NodePort</h5><p>on top of having a cluster-internal IP, expose the service on a port on each node of the cluster (the same port on each node). You’ll be able to contact the service on any :NodePort address.</p><h5 id="LoadBalancer"><a href="#LoadBalancer" class="headerlink" title="LoadBalancer"></a>LoadBalancer</h5><p>on top of having a cluster-internal IP and exposing service on a NodePort also, ask the cloud provider for a load balancer which forwards to the Service exposed as a :NodePort for each Node.</p><h3 id="LoadBalancer-调研"><a href="#LoadBalancer-调研" class="headerlink" title="LoadBalancer 调研"></a>LoadBalancer 调研</h3><pre><code>kubectl run nginx --image=registry.aliyuncs.com/acs/netdia:latestkubectl expose deployment nginx --port=80 --target-port=80 --type=LoadBalancer</code></pre><p>k8s已经将svc expose到node上了，可以借助aliyun slb/dns 给所有pod所在机器上bind vip/dns</p><p><strong><em>注意</em></strong>：<br>NodePort LoadBalancer 都需要kube-proxy进行转发</p><p>最优的解决方案：<br>直接借助CNI 网络插件，将pod网络与aliyun vpc打通 <a href="https://github.com/coreos/flannel/blob/master/Documentation/alicloud-vpc-backend-cn.md" target="_blank" rel="noopener">https://github.com/coreos/flannel/blob/master/Documentation/alicloud-vpc-backend-cn.md</a> 在bind vip/dns<br>局限：需要借助vpc网络；bls环境所以经典网络，还是需要借助kube-proxy进行转发</p><h4 id="Aliyun-ccm-实现"><a href="#Aliyun-ccm-实现" class="headerlink" title="Aliyun ccm 实现"></a>Aliyun ccm 实现</h4><p>参考：<br><a href="https://github.com/AliyunContainerService/alicloud-controller-manager" target="_blank" rel="noopener">https://github.com/AliyunContainerService/alicloud-controller-manager</a></p><p>vip 通过kubectl get svc 可以展现<br>dns建议通过annotation扩展例如：</p><pre class="line-numbers language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Service<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">annotations</span><span class="token punctuation">:</span>      <span class="token comment" spellcheck="true"># 自定义扩展bind DNS功能</span>    <span class="token key atrule">service.beta.kubernetes.io/bind-dns</span><span class="token punctuation">:</span> <span class="token string">"nginx.${REGION}.bls.${INTRANET_DOMAIN}"</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> nginx  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> default<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">ports</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">80</span>    <span class="token key atrule">protocol</span><span class="token punctuation">:</span> TCP    <span class="token key atrule">targetPort</span><span class="token punctuation">:</span> <span class="token number">80</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">run</span><span class="token punctuation">:</span> nginx  <span class="token key atrule">type</span><span class="token punctuation">:</span> LoadBalancer<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="开发-amp-部署"><a href="#开发-amp-部署" class="headerlink" title="开发&amp;部署"></a>开发&amp;部署</h2><p>###<br>实现以下接口</p><p><a href="https://github.com/kubernetes/cloud-provider/blob/master/cloud.go" target="_blank" rel="noopener">https://github.com/kubernetes/cloud-provider/blob/master/cloud.go</a></p><h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><ol start="2"><li>kubelet 启动 –cloud-provider=external<br>这个会在节点加上污点 node.cloudprovider.kubernetes.io/uninitialized 不可调度<br>直到ccm启动成功会移除这个污点</li></ol><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/" target="_blank" rel="noopener">https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/</a><br><a href="https://kubernetes.io/docs/concepts/services-networking/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/services-networking/</a><br><a href="https://jimmysong.io/kubernetes-handbook/practice/service-discovery-and-loadbalancing.html" target="_blank" rel="noopener">https://jimmysong.io/kubernetes-handbook/practice/service-discovery-and-loadbalancing.html</a><br><a href="https://kubernetes.io/docs/concepts/architecture/cloud-controller/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/architecture/cloud-controller/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Kubernetes-Cloud-Controller-Manager&quot;&gt;&lt;a href=&quot;#Kubernetes-Cloud-Controller-Manager&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes Cloud Contr
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="https://bamboox.online/tags/kubernetes/"/>
    
  </entry>
  
</feed>
